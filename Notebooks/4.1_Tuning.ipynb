{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-29T18:58:56.197302Z",
     "start_time": "2024-04-29T18:58:54.999792Z"
    }
   },
   "source": [
    "from itertools import chain\n",
    "from src_draft.utils import LOW_IMP_FEATURES, ZERO_IMP_FEATURES\n",
    "import shared.ml_config_core as ml_config_core\n",
    "import pandas as pd\n",
    "from shared.ml_config_core import ModelConfigsCollection\n",
    "from shared.ml_config_runner import run_tuning_for_configs_collection\n",
    "from shared.definitions import TuningResult\n",
    "\n",
    "from Draft import feature_builder_v2\n",
    "\n",
    "import importlib\n",
    "\n",
    "VERBOSE = True\n",
    "importlib.reload(feature_builder_v2)\n",
    "features_matrix = feature_builder_v2.load_datasets_and_prepare_features(drop_meta_data=True,\n",
    "                                                                        ds_type=feature_builder_v2.DatasetType.BASE)\n",
    "display(\"Distribution of Samples\")\n",
    "value_counts = features_matrix[\"TARGET\"].value_counts()\n",
    "df_value_counts = pd.DataFrame(\n",
    "    {\"Total Rows\": value_counts, \"Proportion\": value_counts / len(features_matrix)}\n",
    ")\n",
    "df_value_counts.round(2)\n",
    "transformers = [\n",
    "    # No feature engineering tuning for for rejected/accepted df\n",
    "    # ml_config_core.AcceptedRejectedDropAllButEmployment,  # Only used for testing\n",
    "]\n",
    "\n",
    "baseline_only_credit_ratings_config = {\n",
    "    # Only uses  ExtScore1/2/3\n",
    "    \"Baseline_Only_CreditRatings\": ml_config_core.ModelPipelineConfig(\n",
    "        model_config=ml_config_core.LGBMTuneAUC(),\n",
    "        transformer_config=ml_config_core.PipelineTransformerConfig(transformers),\n",
    "        data_loader_params={\n",
    "            \"drop_meta_data\": True,\n",
    "            \"ds_type\": feature_builder_v2.DatasetType.BASE_ONLY_CREDIT_RATINGS\n",
    "        })\n",
    "}\n",
    "\n",
    "baseline_only_base_feats = {\n",
    "    # Only includes base table (i.e. no aggregations from client history)\n",
    "    \"LGBM_AUC_Base_Features\": ml_config_core.ModelPipelineConfig(\n",
    "        model_config=ml_config_core.LGBMTuneAUC(),\n",
    "        transformer_config=ml_config_core.PipelineTransformerConfig(transformers),\n",
    "        data_loader_params={\n",
    "            \"drop_meta_data\": True,\n",
    "            \"ds_type\": feature_builder_v2.DatasetType.BASE,\n",
    "        }),\n",
    "}\n",
    "\n",
    "weighted_log_loss_config = {\n",
    "    # Tuned on score combined from logloss and F1 score\n",
    "    \"LGBM_Weighted_LogLoss\": ml_config_core.ModelPipelineConfig(\n",
    "        model_config=ml_config_core.LGBMTuneWeightedLogLossF1(),\n",
    "        transformer_config=ml_config_core.PipelineTransformerConfig(transformers),\n",
    "        data_loader_params={\n",
    "            \"drop_meta_data\": True,\n",
    "            \"drop_cols_post_proc\": ZERO_IMP_FEATURES + LOW_IMP_FEATURES\n",
    "        }),\n",
    "}\n",
    "\n",
    "tune_auc_config: ModelConfigsCollection = {\n",
    "    \"LGBM_AUC\": ml_config_core.ModelPipelineConfig(\n",
    "        model_config=ml_config_core.LGBMTuneAUC(),\n",
    "        transformer_config=ml_config_core.PipelineTransformerConfig(transformers),\n",
    "        data_loader_params={\n",
    "            \"drop_meta_data\": True,\n",
    "            \"ds_type\": feature_builder_v2.DatasetType.FULL,\n",
    "            \"drop_cols_post_proc\": ZERO_IMP_FEATURES + LOW_IMP_FEATURES\n",
    "        }),\n",
    "}\n",
    "\n",
    "dart_tune_auc_config: ModelConfigsCollection = {\n",
    "    \"LGBM_Dart_AUC\": ml_config_core.ModelPipelineConfig(\n",
    "        model_config=ml_config_core.LGBMDartTuneAUC(),\n",
    "        transformer_config=ml_config_core.PipelineTransformerConfig(transformers),\n",
    "        data_loader_params={\n",
    "            \"drop_meta_data\": True,\n",
    "            \"ds_type\": feature_builder_v2.DatasetType.FULL,\n",
    "            \"drop_cols_post_proc\": ZERO_IMP_FEATURES + LOW_IMP_FEATURES\n",
    "        }),\n",
    "}\n",
    "\n",
    "tune_auc_all_features_config: ModelConfigsCollection = {\n",
    "    \"LGBM_AUC_All_Features\": ml_config_core.ModelPipelineConfig(\n",
    "        model_config=ml_config_core.LGBMTuneAUC(),\n",
    "        transformer_config=ml_config_core.PipelineTransformerConfig(transformers),\n",
    "        data_loader_params={\n",
    "            \"drop_meta_data\": True,\n",
    "            \"ds_type\": feature_builder_v2.DatasetType.FULL,\n",
    "            # \"drop_cols_post_proc\": ZERO_IMP_FEATURES + LOW_IMP_FEATURES\n",
    "        }),\n",
    "}\n",
    "\n",
    "configs: ModelConfigsCollection = {\n",
    "    **baseline_only_credit_ratings_config,\n",
    "    # **baseline_only_base_feats,\n",
    "    # **weighted_log_loss_config,\n",
    "    # **tune_auc_config,\n",
    "    # **dart_tune_auc_config,\n",
    "    # **tune_auc_all_features_config\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full DS size: 307511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Distribution of Samples'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": "configs.keys()",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T18:58:57.684543Z",
     "start_time": "2024-04-29T18:58:57.680668Z"
    }
   },
   "id": "a61836a0a428f5e2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Baseline_Only_CreditRatings'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T13:49:16.377842Z",
     "start_time": "2024-04-20T13:49:16.375570Z"
    }
   },
   "id": "eed3fa27393d896b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "tuning_results = run_tuning_for_configs_collection(configs, feature_builder_v2.load_datasets_and_prepare_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T19:08:52.074797Z",
     "start_time": "2024-04-29T18:58:59.047058Z"
    }
   },
   "id": "4b5d63234ede2e6a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 21:58:59,247] A new study created in memory with name: no-name-b2577545-35dc-460c-858e-a1418afeeec7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full DS size: 307511\n",
      "Tunning: - transformers: transformers: 0\n",
      " total options: 0\n",
      "[]\n",
      "search_grid:\n",
      "{}\n",
      "\n",
      " - model: Baseline_Only_CreditRatings n_iters=10 with:\n",
      " {'model__n_estimators': Range(50, 1000, 50, int), 'model__learning_rate': Range(0.01, 0.3, 0.01, float), 'model__max_depth': Range(3, 11, 1, int), 'model__num_leaves': Range(8, 256, 8, int), 'model__min_gain_to_split': Range(0.0, 15.0, 0.5, float), 'model__min_data_in_leaf': Range(0, 3000, 100, int), 'model__lambda_l1': Range(0, 110, 5, int), 'model__lambda_l2': Range(0, 110, 5, int), 'model__bagging_fraction': Range(0.2, 1.0, 0.1, float), 'model__feature_fraction': Range(0.2, 1.0, 0.1, float), 'model__max_bin': Range(50, 500, 25, int)}\n",
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7234, std_test_score:0.00367 train_set_score:0.7252\n",
      "folds val/train: [0.7228, 0.7247, 0.7234, 0.718, 0.7299, 0.7255, 0.7194] / [0.7247, 0.7255, 0.7258, 0.7257, 0.7239, 0.7254, 0.7257], mean fold time: 0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 21:59:01,822] Trial 0 finished with value: 0.723379541466732 and parameters: {'model__n_estimators': 850, 'model__learning_rate': 0.12, 'model__max_depth': 9, 'model__num_leaves': 256, 'model__min_gain_to_split': 8.5, 'model__min_data_in_leaf': 1100, 'model__lambda_l1': 10, 'model__lambda_l2': 105, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 400}. Best is trial 0 with value: 0.723379541466732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7200, std_test_score:0.00654 train_set_score:0.7236\n",
      "folds val/train: [0.7221, 0.7225, 0.7219, 0.7154, 0.7282, 0.7237, 0.7064] / [0.7249, 0.7249, 0.7249, 0.7258, 0.7239, 0.7247, 0.7162], mean fold time: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 21:59:06,546] Trial 1 finished with value: 0.7200250827430056 and parameters: {'model__n_estimators': 150, 'model__learning_rate': 0.02, 'model__max_depth': 11, 'model__num_leaves': 152, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 900, 'model__lambda_l1': 95, 'model__lambda_l2': 70, 'model__bagging_fraction': 0.30000000000000004, 'model__feature_fraction': 0.8, 'model__max_bin': 225}. Best is trial 0 with value: 0.723379541466732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7234, std_test_score:0.00356 train_set_score:0.7271\n",
      "folds val/train: [0.7237, 0.7244, 0.7233, 0.7178, 0.7294, 0.7257, 0.7194] / [0.7272, 0.727, 0.7271, 0.7279, 0.7257, 0.7268, 0.7278], mean fold time: 0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 21:59:09,823] Trial 2 finished with value: 0.7233830542741229 and parameters: {'model__n_estimators': 100, 'model__learning_rate': 0.09, 'model__max_depth': 6, 'model__num_leaves': 112, 'model__min_gain_to_split': 3.5, 'model__min_data_in_leaf': 2800, 'model__lambda_l1': 55, 'model__lambda_l2': 25, 'model__bagging_fraction': 0.8, 'model__feature_fraction': 0.7, 'model__max_bin': 225}. Best is trial 2 with value: 0.7233830542741229.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00371 train_set_score:0.7278\n",
      "folds val/train: [0.7237, 0.7247, 0.7233, 0.7183, 0.7302, 0.7257, 0.7193] / [0.7277, 0.7277, 0.7276, 0.7286, 0.7268, 0.7274, 0.7286], mean fold time: 0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 21:59:13,523] Trial 3 finished with value: 0.7236099236547079 and parameters: {'model__n_estimators': 950, 'model__learning_rate': 0.11, 'model__max_depth': 7, 'model__num_leaves': 144, 'model__min_gain_to_split': 9.0, 'model__min_data_in_leaf': 800, 'model__lambda_l1': 40, 'model__lambda_l2': 40, 'model__bagging_fraction': 0.5, 'model__feature_fraction': 0.7, 'model__max_bin': 500}. Best is trial 3 with value: 0.7236099236547079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7235, std_test_score:0.00387 train_set_score:0.7286\n",
      "folds val/train: [0.724, 0.7248, 0.723, 0.7177, 0.7305, 0.725, 0.7194] / [0.7285, 0.7283, 0.7284, 0.7295, 0.7277, 0.7283, 0.7296], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 21:59:15,776] Trial 4 finished with value: 0.7235028562304875 and parameters: {'model__n_estimators': 700, 'model__learning_rate': 0.3, 'model__max_depth': 6, 'model__num_leaves': 136, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 1700, 'model__lambda_l1': 55, 'model__lambda_l2': 80, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 1.0, 'model__max_bin': 400}. Best is trial 3 with value: 0.7236099236547079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7235, std_test_score:0.00360 train_set_score:0.7251\n",
      "folds val/train: [0.7225, 0.7249, 0.7234, 0.7186, 0.7302, 0.7254, 0.7196] / [0.7245, 0.7251, 0.7254, 0.7262, 0.7238, 0.7251, 0.7257], mean fold time: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 21:59:18,242] Trial 5 finished with value: 0.7235121673799988 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.15000000000000002, 'model__max_depth': 9, 'model__num_leaves': 72, 'model__min_gain_to_split': 9.5, 'model__min_data_in_leaf': 1700, 'model__lambda_l1': 40, 'model__lambda_l2': 45, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 250}. Best is trial 3 with value: 0.7236099236547079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7233, std_test_score:0.00398 train_set_score:0.7265\n",
      "folds val/train: [0.7238, 0.7243, 0.7229, 0.7174, 0.7303, 0.7254, 0.7188] / [0.7262, 0.7264, 0.7265, 0.7274, 0.7254, 0.7262, 0.7273], mean fold time: 0.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 21:59:21,324] Trial 6 finished with value: 0.7232738957988081 and parameters: {'model__n_estimators': 850, 'model__learning_rate': 0.12, 'model__max_depth': 10, 'model__num_leaves': 168, 'model__min_gain_to_split': 8.0, 'model__min_data_in_leaf': 1400, 'model__lambda_l1': 30, 'model__lambda_l2': 35, 'model__bagging_fraction': 0.5, 'model__feature_fraction': 0.5, 'model__max_bin': 50}. Best is trial 3 with value: 0.7236099236547079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7234, std_test_score:0.00399 train_set_score:0.7271\n",
      "folds val/train: [0.7241, 0.7252, 0.7224, 0.7176, 0.7306, 0.7251, 0.7191] / [0.7271, 0.7268, 0.7272, 0.7281, 0.726, 0.7269, 0.7279], mean fold time: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 21:59:23,490] Trial 7 finished with value: 0.7234346004244699 and parameters: {'model__n_estimators': 400, 'model__learning_rate': 0.26, 'model__max_depth': 5, 'model__num_leaves': 56, 'model__min_gain_to_split': 4.5, 'model__min_data_in_leaf': 3000, 'model__lambda_l1': 35, 'model__lambda_l2': 85, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 1.0, 'model__max_bin': 50}. Best is trial 3 with value: 0.7236099236547079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00357 train_set_score:0.7267\n",
      "folds val/train: [0.7236, 0.7245, 0.7233, 0.7186, 0.7304, 0.7248, 0.7196] / [0.7267, 0.7266, 0.7267, 0.7276, 0.7255, 0.7266, 0.7274], mean fold time: 0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 21:59:26,047] Trial 8 finished with value: 0.7235516819846506 and parameters: {'model__n_estimators': 550, 'model__learning_rate': 0.12, 'model__max_depth': 3, 'model__num_leaves': 32, 'model__min_gain_to_split': 14.5, 'model__min_data_in_leaf': 1800, 'model__lambda_l1': 100, 'model__lambda_l2': 30, 'model__bagging_fraction': 0.4, 'model__feature_fraction': 0.9000000000000001, 'model__max_bin': 175}. Best is trial 3 with value: 0.7236099236547079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00360 train_set_score:0.7291\n",
      "folds val/train: [0.7242, 0.7246, 0.7234, 0.7184, 0.7303, 0.7247, 0.7196] / [0.729, 0.7289, 0.7289, 0.7299, 0.7281, 0.7288, 0.7299], mean fold time: 0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 21:59:28,635] Trial 9 finished with value: 0.7235806661629767 and parameters: {'model__n_estimators': 500, 'model__learning_rate': 0.15000000000000002, 'model__max_depth': 11, 'model__num_leaves': 192, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 1100, 'model__lambda_l1': 85, 'model__lambda_l2': 0, 'model__bagging_fraction': 0.2, 'model__feature_fraction': 0.9000000000000001, 'model__max_bin': 275}. Best is trial 3 with value: 0.7236099236547079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7233, std_test_score:0.00380 train_set_score:0.7270\n",
      "folds val/train: [0.7236, 0.7247, 0.723, 0.7174, 0.7296, 0.7259, 0.7191] / [0.7269, 0.7269, 0.7269, 0.7278, 0.7259, 0.7269, 0.7277], mean fold time: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 21:59:31,139] Trial 10 finished with value: 0.7233199768917068 and parameters: {'model__n_estimators': 1000, 'model__learning_rate': 0.22, 'model__max_depth': 8, 'model__num_leaves': 240, 'model__min_gain_to_split': 12.5, 'model__min_data_in_leaf': 300, 'model__lambda_l1': 75, 'model__lambda_l2': 55, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.5, 'model__max_bin': 500}. Best is trial 3 with value: 0.7236099236547079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7232, std_test_score:0.00374 train_set_score:0.7288\n",
      "folds val/train: [0.7237, 0.724, 0.7231, 0.7175, 0.7298, 0.7253, 0.7191] / [0.7288, 0.7288, 0.7285, 0.7297, 0.7281, 0.7281, 0.7294], mean fold time: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 21:59:36,270] Trial 11 finished with value: 0.7232093948227207 and parameters: {'model__n_estimators': 450, 'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__num_leaves': 200, 'model__min_gain_to_split': 0.0, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 80, 'model__lambda_l2': 0, 'model__bagging_fraction': 0.2, 'model__feature_fraction': 0.7, 'model__max_bin': 350}. Best is trial 3 with value: 0.7236099236547079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7233, std_test_score:0.00377 train_set_score:0.7270\n",
      "folds val/train: [0.7234, 0.7247, 0.7229, 0.7177, 0.73, 0.7254, 0.7192] / [0.7269, 0.7268, 0.7269, 0.7277, 0.726, 0.7268, 0.7279], mean fold time: 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 21:59:38,902] Trial 12 finished with value: 0.7233225196383971 and parameters: {'model__n_estimators': 600, 'model__learning_rate': 0.2, 'model__max_depth': 11, 'model__num_leaves': 192, 'model__min_gain_to_split': 11.0, 'model__min_data_in_leaf': 700, 'model__lambda_l1': 75, 'model__lambda_l2': 5, 'model__bagging_fraction': 0.2, 'model__feature_fraction': 0.8, 'model__max_bin': 500}. Best is trial 3 with value: 0.7236099236547079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7235, std_test_score:0.00365 train_set_score:0.7266\n",
      "folds val/train: [0.7236, 0.7245, 0.7233, 0.7179, 0.7299, 0.7255, 0.7196] / [0.7267, 0.7261, 0.7263, 0.7274, 0.7258, 0.7263, 0.7273], mean fold time: 0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 21:59:41,605] Trial 13 finished with value: 0.7234769754706598 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.18000000000000002, 'model__max_depth': 4, 'model__num_leaves': 112, 'model__min_gain_to_split': 2.0, 'model__min_data_in_leaf': 2300, 'model__lambda_l1': 110, 'model__lambda_l2': 15, 'model__bagging_fraction': 0.4, 'model__feature_fraction': 0.6000000000000001, 'model__max_bin': 300}. Best is trial 3 with value: 0.7236099236547079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7235, std_test_score:0.00365 train_set_score:0.7277\n",
      "folds val/train: [0.7237, 0.7243, 0.7235, 0.7183, 0.7299, 0.7257, 0.7192] / [0.7277, 0.7277, 0.7278, 0.7284, 0.7266, 0.7272, 0.7284], mean fold time: 0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 21:59:45,327] Trial 14 finished with value: 0.7234992865013544 and parameters: {'model__n_estimators': 700, 'model__learning_rate': 0.06999999999999999, 'model__max_depth': 8, 'model__num_leaves': 216, 'model__min_gain_to_split': 10.0, 'model__min_data_in_leaf': 600, 'model__lambda_l1': 20, 'model__lambda_l2': 15, 'model__bagging_fraction': 0.4, 'model__feature_fraction': 0.8, 'model__max_bin': 175}. Best is trial 3 with value: 0.7236099236547079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7232, std_test_score:0.00355 train_set_score:0.7311\n",
      "folds val/train: [0.7239, 0.7246, 0.723, 0.7177, 0.7296, 0.7241, 0.7194] / [0.7313, 0.7309, 0.7314, 0.7319, 0.73, 0.7305, 0.732], mean fold time: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 21:59:47,784] Trial 15 finished with value: 0.7231818904017644 and parameters: {'model__n_estimators': 950, 'model__learning_rate': 0.17, 'model__max_depth': 7, 'model__num_leaves': 168, 'model__min_gain_to_split': 5.5, 'model__min_data_in_leaf': 1300, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 0.30000000000000004, 'model__feature_fraction': 0.9000000000000001, 'model__max_bin': 425}. Best is trial 3 with value: 0.7236099236547079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7235, std_test_score:0.00379 train_set_score:0.7271\n",
      "folds val/train: [0.7238, 0.7246, 0.7232, 0.7178, 0.7301, 0.7258, 0.7193] / [0.7269, 0.727, 0.7268, 0.7279, 0.7261, 0.7268, 0.728], mean fold time: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 21:59:50,277] Trial 16 finished with value: 0.723515251625323 and parameters: {'model__n_estimators': 700, 'model__learning_rate': 0.22, 'model__max_depth': 9, 'model__num_leaves': 104, 'model__min_gain_to_split': 12.0, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 65, 'model__lambda_l2': 40, 'model__bagging_fraction': 0.5, 'model__feature_fraction': 0.6000000000000001, 'model__max_bin': 325}. Best is trial 3 with value: 0.7236099236547079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00364 train_set_score:0.7250\n",
      "folds val/train: [0.7229, 0.7246, 0.7234, 0.7185, 0.7302, 0.7258, 0.7195] / [0.7245, 0.725, 0.7253, 0.7261, 0.7236, 0.725, 0.7255], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 21:59:52,665] Trial 17 finished with value: 0.7235580574258457 and parameters: {'model__n_estimators': 350, 'model__learning_rate': 0.15000000000000002, 'model__max_depth': 5, 'model__num_leaves': 216, 'model__min_gain_to_split': 7.5, 'model__min_data_in_leaf': 2200, 'model__lambda_l1': 50, 'model__lambda_l2': 15, 'model__bagging_fraction': 0.8, 'model__feature_fraction': 0.2, 'model__max_bin': 125}. Best is trial 3 with value: 0.7236099236547079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7235, std_test_score:0.00356 train_set_score:0.7299\n",
      "folds val/train: [0.7237, 0.724, 0.7235, 0.7186, 0.7303, 0.7248, 0.7195] / [0.7298, 0.7298, 0.7299, 0.7307, 0.7287, 0.7297, 0.7307], mean fold time: 0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 21:59:56,128] Trial 18 finished with value: 0.7234845008467963 and parameters: {'model__n_estimators': 500, 'model__learning_rate': 0.09, 'model__max_depth': 10, 'model__num_leaves': 184, 'model__min_gain_to_split': 3.0, 'model__min_data_in_leaf': 600, 'model__lambda_l1': 85, 'model__lambda_l2': 70, 'model__bagging_fraction': 0.2, 'model__feature_fraction': 0.9000000000000001, 'model__max_bin': 450}. Best is trial 3 with value: 0.7236099236547079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7231, std_test_score:0.00368 train_set_score:0.7260\n",
      "folds val/train: [0.7234, 0.7242, 0.7233, 0.7174, 0.7296, 0.7249, 0.7192] / [0.726, 0.7259, 0.726, 0.7267, 0.7249, 0.7258, 0.7267], mean fold time: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:00,331] Trial 19 finished with value: 0.7231336750957852 and parameters: {'model__n_estimators': 850, 'model__learning_rate': 0.04, 'model__max_depth': 8, 'model__num_leaves': 8, 'model__min_gain_to_split': 14.0, 'model__min_data_in_leaf': 1100, 'model__lambda_l1': 65, 'model__lambda_l2': 105, 'model__bagging_fraction': 0.5, 'model__feature_fraction': 0.7, 'model__max_bin': 350}. Best is trial 3 with value: 0.7236099236547079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7234, std_test_score:0.00365 train_set_score:0.7279\n",
      "folds val/train: [0.7236, 0.7245, 0.7232, 0.7181, 0.7295, 0.7258, 0.7189] / [0.7281, 0.728, 0.728, 0.7287, 0.7268, 0.7273, 0.7283], mean fold time: 0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:03,955] Trial 20 finished with value: 0.7233697345286594 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.09999999999999999, 'model__max_depth': 6, 'model__num_leaves': 88, 'model__min_gain_to_split': 0.5, 'model__min_data_in_leaf': 2100, 'model__lambda_l1': 45, 'model__lambda_l2': 55, 'model__bagging_fraction': 0.30000000000000004, 'model__feature_fraction': 0.5, 'model__max_bin': 125}. Best is trial 3 with value: 0.7236099236547079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00368 train_set_score:0.7251\n",
      "folds val/train: [0.7234, 0.7247, 0.7234, 0.7184, 0.7304, 0.7259, 0.7197] / [0.7246, 0.7251, 0.7254, 0.7258, 0.7238, 0.7251, 0.7257], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:06,373] Trial 21 finished with value: 0.7237070397176829 and parameters: {'model__n_estimators': 350, 'model__learning_rate': 0.17, 'model__max_depth': 5, 'model__num_leaves': 224, 'model__min_gain_to_split': 7.5, 'model__min_data_in_leaf': 2500, 'model__lambda_l1': 25, 'model__lambda_l2': 15, 'model__bagging_fraction': 0.9000000000000001, 'model__feature_fraction': 0.2, 'model__max_bin': 125}. Best is trial 21 with value: 0.7237070397176829.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7234, std_test_score:0.00344 train_set_score:0.7248\n",
      "folds val/train: [0.7235, 0.7243, 0.7234, 0.7184, 0.7298, 0.7249, 0.7197] / [0.7249, 0.7249, 0.725, 0.7256, 0.7236, 0.7243, 0.7254], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:08,741] Trial 22 finished with value: 0.7234286626376202 and parameters: {'model__n_estimators': 50, 'model__learning_rate': 0.14, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 7.0, 'model__min_data_in_leaf': 2700, 'model__lambda_l1': 25, 'model__lambda_l2': 5, 'model__bagging_fraction': 0.9000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 100}. Best is trial 21 with value: 0.7237070397176829.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00362 train_set_score:0.7254\n",
      "folds val/train: [0.7233, 0.7249, 0.7234, 0.7185, 0.7301, 0.7255, 0.7194] / [0.7249, 0.7255, 0.7256, 0.7261, 0.7242, 0.7252, 0.7262], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:11,262] Trial 23 finished with value: 0.7235883867868997 and parameters: {'model__n_estimators': 400, 'model__learning_rate': 0.18000000000000002, 'model__max_depth': 5, 'model__num_leaves': 144, 'model__min_gain_to_split': 9.0, 'model__min_data_in_leaf': 1000, 'model__lambda_l1': 15, 'model__lambda_l2': 20, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.2, 'model__max_bin': 275}. Best is trial 21 with value: 0.7237070397176829.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00364 train_set_score:0.7252\n",
      "folds val/train: [0.7232, 0.725, 0.7235, 0.7184, 0.7301, 0.7256, 0.7193] / [0.7248, 0.7253, 0.7255, 0.726, 0.7239, 0.7252, 0.7258], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:13,664] Trial 24 finished with value: 0.7235872229017275 and parameters: {'model__n_estimators': 350, 'model__learning_rate': 0.19, 'model__max_depth': 5, 'model__num_leaves': 136, 'model__min_gain_to_split': 9.5, 'model__min_data_in_leaf': 800, 'model__lambda_l1': 15, 'model__lambda_l2': 25, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.2, 'model__max_bin': 175}. Best is trial 21 with value: 0.7237070397176829.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00349 train_set_score:0.7253\n",
      "folds val/train: [0.7238, 0.7248, 0.7235, 0.7189, 0.7302, 0.7254, 0.7197] / [0.725, 0.7252, 0.7255, 0.7262, 0.7242, 0.7252, 0.726], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:15,988] Trial 25 finished with value: 0.7237498166699156 and parameters: {'model__n_estimators': 600, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 5, 'model__num_leaves': 152, 'model__min_gain_to_split': 11.0, 'model__min_data_in_leaf': 2500, 'model__lambda_l1': 5, 'model__lambda_l2': 45, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 200}. Best is trial 25 with value: 0.7237498166699156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00343 train_set_score:0.7251\n",
      "folds val/train: [0.7239, 0.7244, 0.7234, 0.7185, 0.7299, 0.7251, 0.7198] / [0.725, 0.725, 0.7251, 0.7259, 0.7239, 0.7249, 0.7256], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:18,293] Trial 26 finished with value: 0.7235584051461039 and parameters: {'model__n_estimators': 650, 'model__learning_rate': 0.25, 'model__max_depth': 4, 'model__num_leaves': 168, 'model__min_gain_to_split': 11.0, 'model__min_data_in_leaf': 2500, 'model__lambda_l1': 0, 'model__lambda_l2': 50, 'model__bagging_fraction': 0.9000000000000001, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 100}. Best is trial 25 with value: 0.7237498166699156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7238, std_test_score:0.00360 train_set_score:0.7253\n",
      "folds val/train: [0.7241, 0.725, 0.7235, 0.7187, 0.7304, 0.7254, 0.7197] / [0.7255, 0.7253, 0.7255, 0.7262, 0.7237, 0.7252, 0.726], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:20,740] Trial 27 finished with value: 0.7238392358496802 and parameters: {'model__n_estimators': 800, 'model__learning_rate': 0.3, 'model__max_depth': 4, 'model__num_leaves': 160, 'model__min_gain_to_split': 13.0, 'model__min_data_in_leaf': 2000, 'model__lambda_l1': 5, 'model__lambda_l2': 35, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.4, 'model__max_bin': 200}. Best is trial 27 with value: 0.7238392358496802.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00355 train_set_score:0.7252\n",
      "folds val/train: [0.724, 0.7246, 0.7233, 0.7186, 0.7301, 0.7256, 0.7196] / [0.7253, 0.7251, 0.7253, 0.726, 0.724, 0.7251, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:23,049] Trial 28 finished with value: 0.7236930283788949 and parameters: {'model__n_estimators': 800, 'model__learning_rate': 0.3, 'model__max_depth': 4, 'model__num_leaves': 248, 'model__min_gain_to_split': 13.0, 'model__min_data_in_leaf': 2000, 'model__lambda_l1': 5, 'model__lambda_l2': 35, 'model__bagging_fraction': 0.8, 'model__feature_fraction': 0.4, 'model__max_bin': 150}. Best is trial 27 with value: 0.7238392358496802.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00355 train_set_score:0.7253\n",
      "folds val/train: [0.7237, 0.7247, 0.7233, 0.7185, 0.73, 0.7254, 0.7196] / [0.7254, 0.7252, 0.7253, 0.7261, 0.7242, 0.7251, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:25,273] Trial 29 finished with value: 0.7235993751487008 and parameters: {'model__n_estimators': 750, 'model__learning_rate': 0.28, 'model__max_depth': 4, 'model__num_leaves': 216, 'model__min_gain_to_split': 15.0, 'model__min_data_in_leaf': 2500, 'model__lambda_l1': 15, 'model__lambda_l2': 65, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.4, 'model__max_bin': 225}. Best is trial 27 with value: 0.7238392358496802.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00349 train_set_score:0.7249\n",
      "folds val/train: [0.7238, 0.7243, 0.7234, 0.7188, 0.73, 0.7254, 0.7195] / [0.725, 0.7249, 0.725, 0.7258, 0.7237, 0.7247, 0.7256], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:27,582] Trial 30 finished with value: 0.7235976670611767 and parameters: {'model__n_estimators': 600, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 160, 'model__min_gain_to_split': 11.0, 'model__min_data_in_leaf': 2400, 'model__lambda_l1': 10, 'model__lambda_l2': 25, 'model__bagging_fraction': 0.9000000000000001, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 75}. Best is trial 27 with value: 0.7238392358496802.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00355 train_set_score:0.7252\n",
      "folds val/train: [0.724, 0.7246, 0.7233, 0.7186, 0.7301, 0.7256, 0.7196] / [0.7253, 0.7251, 0.7253, 0.726, 0.724, 0.7251, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:29,791] Trial 31 finished with value: 0.7236930283788949 and parameters: {'model__n_estimators': 800, 'model__learning_rate': 0.3, 'model__max_depth': 4, 'model__num_leaves': 248, 'model__min_gain_to_split': 13.0, 'model__min_data_in_leaf': 2000, 'model__lambda_l1': 5, 'model__lambda_l2': 35, 'model__bagging_fraction': 0.8, 'model__feature_fraction': 0.4, 'model__max_bin': 150}. Best is trial 27 with value: 0.7238392358496802.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00357 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7251, 0.7235, 0.7187, 0.7303, 0.7255, 0.7197] / [0.7255, 0.7253, 0.7254, 0.7262, 0.724, 0.7252, 0.726], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:32,037] Trial 32 finished with value: 0.7238501005604496 and parameters: {'model__n_estimators': 800, 'model__learning_rate': 0.27, 'model__max_depth': 4, 'model__num_leaves': 256, 'model__min_gain_to_split': 13.0, 'model__min_data_in_leaf': 1900, 'model__lambda_l1': 5, 'model__lambda_l2': 45, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.4, 'model__max_bin': 200}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00360 train_set_score:0.7253\n",
      "folds val/train: [0.7241, 0.7249, 0.7235, 0.7186, 0.7303, 0.7253, 0.7196] / [0.7253, 0.7253, 0.7253, 0.7261, 0.7239, 0.7251, 0.7259], mean fold time: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:34,239] Trial 33 finished with value: 0.7237470192123034 and parameters: {'model__n_estimators': 900, 'model__learning_rate': 0.28, 'model__max_depth': 6, 'model__num_leaves': 120, 'model__min_gain_to_split': 13.5, 'model__min_data_in_leaf': 2700, 'model__lambda_l1': 25, 'model__lambda_l2': 45, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 200}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7238, std_test_score:0.00353 train_set_score:0.7253\n",
      "folds val/train: [0.7241, 0.7249, 0.7235, 0.7188, 0.7304, 0.7253, 0.7198] / [0.7254, 0.7252, 0.7254, 0.7262, 0.7242, 0.7252, 0.7259], mean fold time: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:36,400] Trial 34 finished with value: 0.7238215975501124 and parameters: {'model__n_estimators': 900, 'model__learning_rate': 0.27, 'model__max_depth': 6, 'model__num_leaves': 112, 'model__min_gain_to_split': 14.0, 'model__min_data_in_leaf': 2800, 'model__lambda_l1': 10, 'model__lambda_l2': 45, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 200}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00355 train_set_score:0.7254\n",
      "folds val/train: [0.7239, 0.7247, 0.7234, 0.7184, 0.73, 0.7254, 0.7196] / [0.7254, 0.7253, 0.7255, 0.7261, 0.7244, 0.7252, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:38,691] Trial 35 finished with value: 0.7236245262269375 and parameters: {'model__n_estimators': 1000, 'model__learning_rate': 0.27, 'model__max_depth': 6, 'model__num_leaves': 88, 'model__min_gain_to_split': 11.5, 'model__min_data_in_leaf': 3000, 'model__lambda_l1': 10, 'model__lambda_l2': 65, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.4, 'model__max_bin': 225}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7233, std_test_score:0.00377 train_set_score:0.7260\n",
      "folds val/train: [0.723, 0.7247, 0.723, 0.7176, 0.73, 0.7252, 0.7193] / [0.7259, 0.7259, 0.726, 0.7268, 0.7251, 0.726, 0.7266], mean fold time: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:41,111] Trial 36 finished with value: 0.7232545953452865 and parameters: {'model__n_estimators': 900, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 3, 'model__num_leaves': 128, 'model__min_gain_to_split': 14.0, 'model__min_data_in_leaf': 1800, 'model__lambda_l1': 0, 'model__lambda_l2': 50, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.5, 'model__max_bin': 250}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00352 train_set_score:0.7252\n",
      "folds val/train: [0.7237, 0.7249, 0.7235, 0.7187, 0.7302, 0.7254, 0.7198] / [0.7249, 0.7253, 0.7254, 0.7262, 0.7239, 0.7252, 0.7258], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:43,386] Trial 37 finished with value: 0.7237482751518669 and parameters: {'model__n_estimators': 750, 'model__learning_rate': 0.22, 'model__max_depth': 5, 'model__num_leaves': 96, 'model__min_gain_to_split': 15.0, 'model__min_data_in_leaf': 2800, 'model__lambda_l1': 10, 'model__lambda_l2': 45, 'model__bagging_fraction': 0.8, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 200}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00359 train_set_score:0.7254\n",
      "folds val/train: [0.7236, 0.7248, 0.7236, 0.7186, 0.7303, 0.7256, 0.7196] / [0.7254, 0.7252, 0.7255, 0.7262, 0.7244, 0.7252, 0.7261], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:45,677] Trial 38 finished with value: 0.7237261661038529 and parameters: {'model__n_estimators': 800, 'model__learning_rate': 0.28, 'model__max_depth': 6, 'model__num_leaves': 72, 'model__min_gain_to_split': 12.0, 'model__min_data_in_leaf': 1500, 'model__lambda_l1': 35, 'model__lambda_l2': 60, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 250}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7235, std_test_score:0.00369 train_set_score:0.7264\n",
      "folds val/train: [0.724, 0.7248, 0.723, 0.7176, 0.7294, 0.726, 0.7194] / [0.7264, 0.7263, 0.7265, 0.7271, 0.7254, 0.7261, 0.7271], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:48,053] Trial 39 finished with value: 0.7234531579451751 and parameters: {'model__n_estimators': 900, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 4, 'model__num_leaves': 152, 'model__min_gain_to_split': 13.5, 'model__min_data_in_leaf': 2000, 'model__lambda_l1': 20, 'model__lambda_l2': 85, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.5, 'model__max_bin': 200}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00352 train_set_score:0.7253\n",
      "folds val/train: [0.7238, 0.7247, 0.7234, 0.7187, 0.73, 0.7254, 0.7195] / [0.7254, 0.7254, 0.7255, 0.7262, 0.7237, 0.7252, 0.726], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:50,334] Trial 40 finished with value: 0.7236325879167873 and parameters: {'model__n_estimators': 650, 'model__learning_rate': 0.29000000000000004, 'model__max_depth': 6, 'model__num_leaves': 64, 'model__min_gain_to_split': 12.5, 'model__min_data_in_leaf': 2300, 'model__lambda_l1': 5, 'model__lambda_l2': 40, 'model__bagging_fraction': 0.8, 'model__feature_fraction': 0.4, 'model__max_bin': 225}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00352 train_set_score:0.7252\n",
      "folds val/train: [0.7237, 0.7249, 0.7235, 0.7187, 0.7302, 0.7254, 0.7198] / [0.7249, 0.7253, 0.7254, 0.7262, 0.7239, 0.7252, 0.7258], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:52,622] Trial 41 finished with value: 0.7237482751518669 and parameters: {'model__n_estimators': 750, 'model__learning_rate': 0.22, 'model__max_depth': 5, 'model__num_leaves': 96, 'model__min_gain_to_split': 15.0, 'model__min_data_in_leaf': 2800, 'model__lambda_l1': 10, 'model__lambda_l2': 45, 'model__bagging_fraction': 0.8, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 200}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00358 train_set_score:0.7254\n",
      "folds val/train: [0.7237, 0.7248, 0.7236, 0.7186, 0.7301, 0.7256, 0.7194] / [0.7254, 0.7253, 0.7254, 0.7261, 0.7242, 0.7252, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:54,936] Trial 42 finished with value: 0.723687426274844 and parameters: {'model__n_estimators': 750, 'model__learning_rate': 0.26, 'model__max_depth': 5, 'model__num_leaves': 120, 'model__min_gain_to_split': 14.5, 'model__min_data_in_leaf': 3000, 'model__lambda_l1': 0, 'model__lambda_l2': 30, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 175}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7238, std_test_score:0.00351 train_set_score:0.7253\n",
      "folds val/train: [0.7241, 0.725, 0.7235, 0.7188, 0.7303, 0.7254, 0.7198] / [0.7254, 0.7253, 0.7253, 0.7261, 0.724, 0.7252, 0.7257], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:57,327] Trial 43 finished with value: 0.723845733076898 and parameters: {'model__n_estimators': 850, 'model__learning_rate': 0.21000000000000002, 'model__max_depth': 4, 'model__num_leaves': 80, 'model__min_gain_to_split': 14.0, 'model__min_data_in_leaf': 2800, 'model__lambda_l1': 15, 'model__lambda_l2': 50, 'model__bagging_fraction': 0.8, 'model__feature_fraction': 0.2, 'model__max_bin': 200}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00350 train_set_score:0.7252\n",
      "folds val/train: [0.7237, 0.7246, 0.7234, 0.7187, 0.73, 0.7256, 0.7196] / [0.7253, 0.7251, 0.7252, 0.726, 0.724, 0.725, 0.7257], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:00:59,609] Trial 44 finished with value: 0.7236488059933611 and parameters: {'model__n_estimators': 950, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 56, 'model__min_gain_to_split': 10.5, 'model__min_data_in_leaf': 1600, 'model__lambda_l1': 20, 'model__lambda_l2': 75, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.2, 'model__max_bin': 150}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7238, std_test_score:0.00360 train_set_score:0.7253\n",
      "folds val/train: [0.7237, 0.7249, 0.7234, 0.7187, 0.7303, 0.7256, 0.7197] / [0.7254, 0.7252, 0.7254, 0.7262, 0.7242, 0.7252, 0.7258], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:01,911] Trial 45 finished with value: 0.7237535759298072 and parameters: {'model__n_estimators': 850, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 4, 'model__num_leaves': 48, 'model__min_gain_to_split': 13.0, 'model__min_data_in_leaf': 2600, 'model__lambda_l1': 30, 'model__lambda_l2': 30, 'model__bagging_fraction': 0.8, 'model__feature_fraction': 0.2, 'model__max_bin': 250}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00353 train_set_score:0.7253\n",
      "folds val/train: [0.7233, 0.7248, 0.7236, 0.7185, 0.7302, 0.7253, 0.7199] / [0.7249, 0.7254, 0.7254, 0.7262, 0.7239, 0.7253, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:04,252] Trial 46 finished with value: 0.723635059163774 and parameters: {'model__n_estimators': 850, 'model__learning_rate': 0.21000000000000002, 'model__max_depth': 4, 'model__num_leaves': 32, 'model__min_gain_to_split': 14.0, 'model__min_data_in_leaf': 2700, 'model__lambda_l1': 15, 'model__lambda_l2': 35, 'model__bagging_fraction': 0.8, 'model__feature_fraction': 0.2, 'model__max_bin': 300}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00358 train_set_score:0.7253\n",
      "folds val/train: [0.7236, 0.7247, 0.7235, 0.7185, 0.7304, 0.7255, 0.7199] / [0.7254, 0.7252, 0.7254, 0.7261, 0.7241, 0.7251, 0.7258], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:06,458] Trial 47 finished with value: 0.7237185690876233 and parameters: {'model__n_estimators': 1000, 'model__learning_rate': 0.27, 'model__max_depth': 3, 'model__num_leaves': 48, 'model__min_gain_to_split': 12.5, 'model__min_data_in_leaf': 2800, 'model__lambda_l1': 35, 'model__lambda_l2': 30, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.2, 'model__max_bin': 250}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00359 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7249, 0.7236, 0.7183, 0.73, 0.7255, 0.7196] / [0.7254, 0.7252, 0.7254, 0.7261, 0.7244, 0.7252, 0.7258], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:08,780] Trial 48 finished with value: 0.7236997390726315 and parameters: {'model__n_estimators': 850, 'model__learning_rate': 0.23, 'model__max_depth': 4, 'model__num_leaves': 32, 'model__min_gain_to_split': 13.0, 'model__min_data_in_leaf': 1800, 'model__lambda_l1': 30, 'model__lambda_l2': 50, 'model__bagging_fraction': 0.9000000000000001, 'model__feature_fraction': 0.2, 'model__max_bin': 275}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00351 train_set_score:0.7254\n",
      "folds val/train: [0.7238, 0.7247, 0.7237, 0.7186, 0.7301, 0.7253, 0.7198] / [0.7254, 0.7253, 0.7254, 0.7262, 0.7242, 0.7252, 0.7259], mean fold time: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:10,941] Trial 49 finished with value: 0.7237209394104017 and parameters: {'model__n_estimators': 900, 'model__learning_rate': 0.29000000000000004, 'model__max_depth': 3, 'model__num_leaves': 72, 'model__min_gain_to_split': 12.0, 'model__min_data_in_leaf': 2300, 'model__lambda_l1': 30, 'model__lambda_l2': 60, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.4, 'model__max_bin': 300}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00354 train_set_score:0.7253\n",
      "folds val/train: [0.7239, 0.725, 0.7234, 0.7186, 0.7301, 0.7254, 0.7197] / [0.7254, 0.7253, 0.7254, 0.7261, 0.724, 0.7252, 0.7257], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:13,335] Trial 50 finished with value: 0.7237347773106576 and parameters: {'model__n_estimators': 950, 'model__learning_rate': 0.2, 'model__max_depth': 4, 'model__num_leaves': 8, 'model__min_gain_to_split': 13.5, 'model__min_data_in_leaf': 1300, 'model__lambda_l1': 20, 'model__lambda_l2': 40, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 275}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7238, std_test_score:0.00354 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7249, 0.7235, 0.7187, 0.7302, 0.7253, 0.7198] / [0.7254, 0.7251, 0.7254, 0.7262, 0.7241, 0.7252, 0.726], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:15,674] Trial 51 finished with value: 0.7237828008592189 and parameters: {'model__n_estimators': 800, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 5, 'model__num_leaves': 80, 'model__min_gain_to_split': 14.5, 'model__min_data_in_leaf': 2600, 'model__lambda_l1': 5, 'model__lambda_l2': 40, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 200}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00356 train_set_score:0.7254\n",
      "folds val/train: [0.7238, 0.7248, 0.7234, 0.7185, 0.73, 0.7255, 0.7195] / [0.7254, 0.7253, 0.7254, 0.7261, 0.7244, 0.7252, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:17,941] Trial 52 finished with value: 0.7236500848255509 and parameters: {'model__n_estimators': 800, 'model__learning_rate': 0.27, 'model__max_depth': 4, 'model__num_leaves': 80, 'model__min_gain_to_split': 14.5, 'model__min_data_in_leaf': 2600, 'model__lambda_l1': 5, 'model__lambda_l2': 30, 'model__bagging_fraction': 0.8, 'model__feature_fraction': 0.2, 'model__max_bin': 225}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00355 train_set_score:0.7253\n",
      "folds val/train: [0.7238, 0.725, 0.7235, 0.7187, 0.73, 0.7255, 0.7194] / [0.7253, 0.7252, 0.7253, 0.7261, 0.7241, 0.7251, 0.7258], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:20,241] Trial 53 finished with value: 0.7236979326225255 and parameters: {'model__n_estimators': 700, 'model__learning_rate': 0.25, 'model__max_depth': 5, 'model__num_leaves': 48, 'model__min_gain_to_split': 14.0, 'model__min_data_in_leaf': 2200, 'model__lambda_l1': 15, 'model__lambda_l2': 50, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.4, 'model__max_bin': 175}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7231, std_test_score:0.00353 train_set_score:0.7243\n",
      "folds val/train: [0.7227, 0.7238, 0.7223, 0.7181, 0.7299, 0.725, 0.7197] / [0.7243, 0.7243, 0.7246, 0.7251, 0.7227, 0.724, 0.725], mean fold time: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:22,386] Trial 54 finished with value: 0.7230546106062158 and parameters: {'model__n_estimators': 800, 'model__learning_rate': 0.01, 'model__max_depth': 6, 'model__num_leaves': 104, 'model__min_gain_to_split': 12.5, 'model__min_data_in_leaf': 2900, 'model__lambda_l1': 0, 'model__lambda_l2': 40, 'model__bagging_fraction': 0.8, 'model__feature_fraction': 0.2, 'model__max_bin': 250}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00352 train_set_score:0.7252\n",
      "folds val/train: [0.7235, 0.7246, 0.7233, 0.7187, 0.7303, 0.7255, 0.7198] / [0.7248, 0.7252, 0.7253, 0.726, 0.7239, 0.7251, 0.7257], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:24,647] Trial 55 finished with value: 0.7236785735795611 and parameters: {'model__n_estimators': 850, 'model__learning_rate': 0.23, 'model__max_depth': 7, 'model__num_leaves': 40, 'model__min_gain_to_split': 14.5, 'model__min_data_in_leaf': 2900, 'model__lambda_l1': 10, 'model__lambda_l2': 20, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 150}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7234, std_test_score:0.00374 train_set_score:0.7264\n",
      "folds val/train: [0.7237, 0.7244, 0.7234, 0.7171, 0.7295, 0.7258, 0.7197] / [0.7264, 0.7261, 0.7265, 0.7271, 0.7254, 0.726, 0.7271], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:26,926] Trial 56 finished with value: 0.7233816957029422 and parameters: {'model__n_estimators': 950, 'model__learning_rate': 0.29000000000000004, 'model__max_depth': 4, 'model__num_leaves': 80, 'model__min_gain_to_split': 13.5, 'model__min_data_in_leaf': 2600, 'model__lambda_l1': 20, 'model__lambda_l2': 35, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.5, 'model__max_bin': 225}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7233, std_test_score:0.00366 train_set_score:0.7265\n",
      "folds val/train: [0.7235, 0.7246, 0.7232, 0.7175, 0.7295, 0.7253, 0.7192] / [0.7266, 0.7264, 0.7265, 0.7273, 0.7255, 0.7263, 0.727], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:29,281] Trial 57 finished with value: 0.723254202359397 and parameters: {'model__n_estimators': 850, 'model__learning_rate': 0.26, 'model__max_depth': 5, 'model__num_leaves': 112, 'model__min_gain_to_split': 11.5, 'model__min_data_in_leaf': 1900, 'model__lambda_l1': 45, 'model__lambda_l2': 25, 'model__bagging_fraction': 0.5, 'model__feature_fraction': 0.6000000000000001, 'model__max_bin': 175}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00359 train_set_score:0.7251\n",
      "folds val/train: [0.7238, 0.7249, 0.7236, 0.7185, 0.7302, 0.7252, 0.7195] / [0.7252, 0.7252, 0.7252, 0.726, 0.7238, 0.725, 0.7255], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:31,630] Trial 58 finished with value: 0.7236738828930936 and parameters: {'model__n_estimators': 650, 'model__learning_rate': 0.2, 'model__max_depth': 7, 'model__num_leaves': 24, 'model__min_gain_to_split': 13.0, 'model__min_data_in_leaf': 2400, 'model__lambda_l1': 60, 'model__lambda_l2': 55, 'model__bagging_fraction': 0.9000000000000001, 'model__feature_fraction': 0.2, 'model__max_bin': 200}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00352 train_set_score:0.7256\n",
      "folds val/train: [0.7237, 0.7248, 0.7234, 0.7188, 0.7302, 0.7255, 0.7198] / [0.7256, 0.7255, 0.7256, 0.7264, 0.7243, 0.7254, 0.7261], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:33,935] Trial 59 finished with value: 0.7237331976622564 and parameters: {'model__n_estimators': 900, 'model__learning_rate': 0.27, 'model__max_depth': 3, 'model__num_leaves': 64, 'model__min_gain_to_split': 5.0, 'model__min_data_in_leaf': 2200, 'model__lambda_l1': 5, 'model__lambda_l2': 45, 'model__bagging_fraction': 0.8, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 325}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7234, std_test_score:0.00367 train_set_score:0.7250\n",
      "folds val/train: [0.7225, 0.7248, 0.7233, 0.7181, 0.7301, 0.7255, 0.7196] / [0.7245, 0.7253, 0.7255, 0.7251, 0.7238, 0.7252, 0.7254], mean fold time: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:36,361] Trial 60 finished with value: 0.7234181233953185 and parameters: {'model__n_estimators': 750, 'model__learning_rate': 0.13, 'model__max_depth': 5, 'model__num_leaves': 200, 'model__min_gain_to_split': 10.0, 'model__min_data_in_leaf': 2600, 'model__lambda_l1': 25, 'model__lambda_l2': 60, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 250}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7238, std_test_score:0.00357 train_set_score:0.7253\n",
      "folds val/train: [0.7242, 0.7249, 0.7234, 0.7188, 0.7304, 0.7254, 0.7197] / [0.7254, 0.7253, 0.7254, 0.7262, 0.7241, 0.7252, 0.7258], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:38,651] Trial 61 finished with value: 0.7238300417639391 and parameters: {'model__n_estimators': 700, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 4, 'model__num_leaves': 176, 'model__min_gain_to_split': 12.0, 'model__min_data_in_leaf': 2400, 'model__lambda_l1': 5, 'model__lambda_l2': 110, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 200}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00356 train_set_score:0.7253\n",
      "folds val/train: [0.7238, 0.7249, 0.7236, 0.7186, 0.73, 0.7256, 0.7195] / [0.7253, 0.7253, 0.7254, 0.7261, 0.724, 0.7251, 0.7258], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:40,987] Trial 62 finished with value: 0.7237136729830104 and parameters: {'model__n_estimators': 800, 'model__learning_rate': 0.23, 'model__max_depth': 4, 'model__num_leaves': 184, 'model__min_gain_to_split': 14.5, 'model__min_data_in_leaf': 2900, 'model__lambda_l1': 0, 'model__lambda_l2': 95, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 175}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7238, std_test_score:0.00354 train_set_score:0.7253\n",
      "folds val/train: [0.724, 0.7249, 0.7234, 0.7188, 0.7303, 0.7254, 0.7196] / [0.7254, 0.7253, 0.7253, 0.7262, 0.724, 0.7251, 0.7258], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:43,288] Trial 63 finished with value: 0.7237751977629815 and parameters: {'model__n_estimators': 700, 'model__learning_rate': 0.25, 'model__max_depth': 4, 'model__num_leaves': 184, 'model__min_gain_to_split': 12.0, 'model__min_data_in_leaf': 2400, 'model__lambda_l1': 15, 'model__lambda_l2': 105, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 200}. Best is trial 32 with value: 0.7238501005604496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00373 train_set_score:0.7252\n",
      "folds val/train: [0.724, 0.7248, 0.7236, 0.7186, 0.7307, 0.7259, 0.7197] / [0.7253, 0.7251, 0.7253, 0.7261, 0.724, 0.725, 0.7258], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:45,586] Trial 64 finished with value: 0.7238869400023052 and parameters: {'model__n_estimators': 700, 'model__learning_rate': 0.25, 'model__max_depth': 4, 'model__num_leaves': 168, 'model__min_gain_to_split': 12.0, 'model__min_data_in_leaf': 2100, 'model__lambda_l1': 15, 'model__lambda_l2': 105, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7232, std_test_score:0.00360 train_set_score:0.7264\n",
      "folds val/train: [0.7239, 0.7243, 0.7234, 0.7174, 0.7291, 0.7249, 0.7191] / [0.7264, 0.7262, 0.7263, 0.7271, 0.7255, 0.7261, 0.7271], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:47,916] Trial 65 finished with value: 0.7231537882663426 and parameters: {'model__n_estimators': 650, 'model__learning_rate': 0.29000000000000004, 'model__max_depth': 5, 'model__num_leaves': 176, 'model__min_gain_to_split': 8.5, 'model__min_data_in_leaf': 2100, 'model__lambda_l1': 10, 'model__lambda_l2': 110, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.5, 'model__max_bin': 100}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00366 train_set_score:0.7252\n",
      "folds val/train: [0.724, 0.7246, 0.7237, 0.7186, 0.7304, 0.726, 0.7196] / [0.7253, 0.7252, 0.7253, 0.7261, 0.7237, 0.7251, 0.726], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:50,241] Trial 66 finished with value: 0.723856596218517 and parameters: {'model__n_estimators': 750, 'model__learning_rate': 0.21000000000000002, 'model__max_depth': 3, 'model__num_leaves': 128, 'model__min_gain_to_split': 11.5, 'model__min_data_in_leaf': 2100, 'model__lambda_l1': 5, 'model__lambda_l2': 95, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7234, std_test_score:0.00345 train_set_score:0.7248\n",
      "folds val/train: [0.7229, 0.7245, 0.7234, 0.7186, 0.7298, 0.7254, 0.7196] / [0.7243, 0.7248, 0.7249, 0.7258, 0.7236, 0.7247, 0.7253], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:52,466] Trial 67 finished with value: 0.7234492830642074 and parameters: {'model__n_estimators': 550, 'model__learning_rate': 0.21000000000000002, 'model__max_depth': 3, 'model__num_leaves': 136, 'model__min_gain_to_split': 11.5, 'model__min_data_in_leaf': 2100, 'model__lambda_l1': 15, 'model__lambda_l2': 95, 'model__bagging_fraction': 0.5, 'model__feature_fraction': 0.4, 'model__max_bin': 75}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00363 train_set_score:0.7253\n",
      "folds val/train: [0.724, 0.7247, 0.7237, 0.7187, 0.7304, 0.7258, 0.7196] / [0.7254, 0.7252, 0.7253, 0.7261, 0.7242, 0.7251, 0.7257], mean fold time: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:54,675] Trial 68 finished with value: 0.7238560564852857 and parameters: {'model__n_estimators': 700, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 160, 'model__min_gain_to_split': 10.5, 'model__min_data_in_leaf': 1700, 'model__lambda_l1': 0, 'model__lambda_l2': 100, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7233, std_test_score:0.00368 train_set_score:0.7257\n",
      "folds val/train: [0.724, 0.7241, 0.7227, 0.718, 0.7297, 0.7257, 0.719] / [0.7257, 0.7258, 0.7257, 0.7267, 0.7246, 0.7254, 0.7263], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:56,950] Trial 69 finished with value: 0.7233022009927337 and parameters: {'model__n_estimators': 700, 'model__learning_rate': 0.3, 'model__max_depth': 3, 'model__num_leaves': 160, 'model__min_gain_to_split': 10.0, 'model__min_data_in_leaf': 1700, 'model__lambda_l1': 0, 'model__lambda_l2': 100, 'model__bagging_fraction': 0.5, 'model__feature_fraction': 0.6000000000000001, 'model__max_bin': 125}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7232, std_test_score:0.00374 train_set_score:0.7254\n",
      "folds val/train: [0.7233, 0.7244, 0.7229, 0.7175, 0.73, 0.7252, 0.7194] / [0.7254, 0.7255, 0.7254, 0.7262, 0.7244, 0.7251, 0.7261], mean fold time: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:01:59,486] Trial 70 finished with value: 0.7232384990090015 and parameters: {'model__n_estimators': 600, 'model__learning_rate': 0.17, 'model__max_depth': 3, 'model__num_leaves': 144, 'model__min_gain_to_split': 11.5, 'model__min_data_in_leaf': 1900, 'model__lambda_l1': 95, 'model__lambda_l2': 110, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.5, 'model__max_bin': 75}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00361 train_set_score:0.7253\n",
      "folds val/train: [0.724, 0.7247, 0.7236, 0.7187, 0.7304, 0.7258, 0.7197] / [0.7253, 0.7252, 0.7253, 0.7261, 0.7241, 0.7251, 0.7259], mean fold time: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:01,689] Trial 71 finished with value: 0.7238534726790796 and parameters: {'model__n_estimators': 750, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 128, 'model__min_gain_to_split': 10.5, 'model__min_data_in_leaf': 1600, 'model__lambda_l1': 10, 'model__lambda_l2': 95, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00361 train_set_score:0.7253\n",
      "folds val/train: [0.7241, 0.7247, 0.7236, 0.7187, 0.7304, 0.7259, 0.7197] / [0.7254, 0.7252, 0.7254, 0.7261, 0.7242, 0.7251, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:03,922] Trial 72 finished with value: 0.7238743050742814 and parameters: {'model__n_estimators': 750, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 200, 'model__min_gain_to_split': 10.5, 'model__min_data_in_leaf': 1500, 'model__lambda_l1': 5, 'model__lambda_l2': 100, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00376 train_set_score:0.7248\n",
      "folds val/train: [0.7238, 0.7245, 0.7231, 0.7184, 0.7306, 0.7254, 0.7192] / [0.7247, 0.7246, 0.7248, 0.7256, 0.7236, 0.7246, 0.7255], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:06,176] Trial 73 finished with value: 0.7235715487029581 and parameters: {'model__n_estimators': 750, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 200, 'model__min_gain_to_split': 10.5, 'model__min_data_in_leaf': 1500, 'model__lambda_l1': 10, 'model__lambda_l2': 90, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 50}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7233, std_test_score:0.00370 train_set_score:0.7259\n",
      "folds val/train: [0.7243, 0.7237, 0.723, 0.7178, 0.7296, 0.7258, 0.719] / [0.7259, 0.7258, 0.726, 0.7267, 0.7248, 0.7255, 0.7265], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:08,423] Trial 74 finished with value: 0.7233061093549665 and parameters: {'model__n_estimators': 750, 'model__learning_rate': 0.29000000000000004, 'model__max_depth': 3, 'model__num_leaves': 256, 'model__min_gain_to_split': 9.0, 'model__min_data_in_leaf': 1300, 'model__lambda_l1': 0, 'model__lambda_l2': 100, 'model__bagging_fraction': 0.5, 'model__feature_fraction': 0.5, 'model__max_bin': 125}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00345 train_set_score:0.7251\n",
      "folds val/train: [0.7238, 0.7243, 0.7235, 0.7186, 0.73, 0.7251, 0.7197] / [0.725, 0.7251, 0.7251, 0.7258, 0.7241, 0.7249, 0.7256], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:10,646] Trial 75 finished with value: 0.7235651754029092 and parameters: {'model__n_estimators': 700, 'model__learning_rate': 0.3, 'model__max_depth': 3, 'model__num_leaves': 160, 'model__min_gain_to_split': 10.5, 'model__min_data_in_leaf': 1600, 'model__lambda_l1': 10, 'model__lambda_l2': 100, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 100}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00350 train_set_score:0.7253\n",
      "folds val/train: [0.7238, 0.7246, 0.7236, 0.7188, 0.73, 0.7255, 0.7195] / [0.7253, 0.7251, 0.7253, 0.726, 0.7241, 0.7251, 0.7258], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:12,878] Trial 76 finished with value: 0.7236723007342756 and parameters: {'model__n_estimators': 650, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 208, 'model__min_gain_to_split': 9.5, 'model__min_data_in_leaf': 1400, 'model__lambda_l1': 5, 'model__lambda_l2': 85, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 150}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7235, std_test_score:0.00373 train_set_score:0.7259\n",
      "folds val/train: [0.7245, 0.7249, 0.7228, 0.7179, 0.7296, 0.7259, 0.719] / [0.726, 0.7257, 0.7258, 0.7266, 0.7247, 0.7256, 0.7266], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:15,220] Trial 77 finished with value: 0.7235172994548761 and parameters: {'model__n_estimators': 550, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 128, 'model__min_gain_to_split': 8.0, 'model__min_data_in_leaf': 1600, 'model__lambda_l1': 20, 'model__lambda_l2': 90, 'model__bagging_fraction': 0.5, 'model__feature_fraction': 0.7, 'model__max_bin': 125}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00352 train_set_score:0.7250\n",
      "folds val/train: [0.7238, 0.7244, 0.7234, 0.7187, 0.7301, 0.7254, 0.7195] / [0.725, 0.7249, 0.725, 0.7258, 0.7238, 0.7247, 0.7255], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:17,436] Trial 78 finished with value: 0.7235990179270421 and parameters: {'model__n_estimators': 750, 'model__learning_rate': 0.3, 'model__max_depth': 4, 'model__num_leaves': 144, 'model__min_gain_to_split': 11.0, 'model__min_data_in_leaf': 1800, 'model__lambda_l1': 5, 'model__lambda_l2': 80, 'model__bagging_fraction': 0.4, 'model__feature_fraction': 0.4, 'model__max_bin': 75}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7233, std_test_score:0.00358 train_set_score:0.7269\n",
      "folds val/train: [0.7237, 0.7247, 0.7234, 0.7176, 0.7293, 0.725, 0.7192] / [0.727, 0.7267, 0.7269, 0.7276, 0.7258, 0.7267, 0.7276], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:19,814] Trial 79 finished with value: 0.7232841588615144 and parameters: {'model__n_estimators': 800, 'model__learning_rate': 0.28, 'model__max_depth': 10, 'model__num_leaves': 168, 'model__min_gain_to_split': 9.5, 'model__min_data_in_leaf': 1900, 'model__lambda_l1': 0, 'model__lambda_l2': 105, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.5, 'model__max_bin': 100}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7232, std_test_score:0.00362 train_set_score:0.7257\n",
      "folds val/train: [0.7236, 0.7243, 0.7229, 0.7182, 0.7298, 0.725, 0.7189] / [0.7256, 0.7257, 0.7257, 0.7264, 0.7247, 0.7255, 0.7263], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:22,101] Trial 80 finished with value: 0.7232284765315471 and parameters: {'model__n_estimators': 600, 'model__learning_rate': 0.27, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 12.5, 'model__min_data_in_leaf': 1200, 'model__lambda_l1': 15, 'model__lambda_l2': 95, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.5, 'model__max_bin': 150}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00366 train_set_score:0.7253\n",
      "folds val/train: [0.7241, 0.7247, 0.7236, 0.7186, 0.7305, 0.7259, 0.7197] / [0.7253, 0.7252, 0.7254, 0.7261, 0.724, 0.7251, 0.7258], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:24,364] Trial 81 finished with value: 0.72388034899886 and parameters: {'model__n_estimators': 700, 'model__learning_rate': 0.25, 'model__max_depth': 4, 'model__num_leaves': 176, 'model__min_gain_to_split': 12.0, 'model__min_data_in_leaf': 2000, 'model__lambda_l1': 5, 'model__lambda_l2': 110, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7238, std_test_score:0.00368 train_set_score:0.7253\n",
      "folds val/train: [0.724, 0.7248, 0.7236, 0.7185, 0.7305, 0.7258, 0.7197] / [0.7253, 0.7252, 0.7253, 0.7261, 0.724, 0.7251, 0.7258], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:26,626] Trial 82 finished with value: 0.7238285916441382 and parameters: {'model__n_estimators': 700, 'model__learning_rate': 0.25, 'model__max_depth': 4, 'model__num_leaves': 152, 'model__min_gain_to_split': 11.0, 'model__min_data_in_leaf': 1700, 'model__lambda_l1': 10, 'model__lambda_l2': 100, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00339 train_set_score:0.7251\n",
      "folds val/train: [0.7238, 0.7243, 0.7235, 0.7186, 0.7298, 0.7252, 0.7198] / [0.725, 0.725, 0.7251, 0.7258, 0.7241, 0.7248, 0.7258], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:28,926] Trial 83 finished with value: 0.7235764026552644 and parameters: {'model__n_estimators': 650, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 192, 'model__min_gain_to_split': 10.5, 'model__min_data_in_leaf': 2000, 'model__lambda_l1': 5, 'model__lambda_l2': 105, 'model__bagging_fraction': 0.5, 'model__feature_fraction': 0.4, 'model__max_bin': 100}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7234, std_test_score:0.00379 train_set_score:0.7246\n",
      "folds val/train: [0.7231, 0.7246, 0.723, 0.7182, 0.7306, 0.7252, 0.7193] / [0.7241, 0.7247, 0.7248, 0.7254, 0.7234, 0.7245, 0.7254], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:31,241] Trial 84 finished with value: 0.7234305609379048 and parameters: {'model__n_estimators': 750, 'model__learning_rate': 0.19, 'model__max_depth': 4, 'model__num_leaves': 168, 'model__min_gain_to_split': 11.5, 'model__min_data_in_leaf': 1700, 'model__lambda_l1': 0, 'model__lambda_l2': 110, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 50}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7235, std_test_score:0.00352 train_set_score:0.7264\n",
      "folds val/train: [0.7237, 0.724, 0.7233, 0.7186, 0.7302, 0.7253, 0.7197] / [0.7264, 0.7262, 0.7265, 0.7273, 0.7253, 0.7262, 0.727], mean fold time: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:33,372] Trial 85 finished with value: 0.7235427370458476 and parameters: {'model__n_estimators': 800, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 136, 'model__min_gain_to_split': 12.5, 'model__min_data_in_leaf': 1900, 'model__lambda_l1': 5, 'model__lambda_l2': 90, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 1.0, 'model__max_bin': 125}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7235, std_test_score:0.00357 train_set_score:0.7265\n",
      "folds val/train: [0.7237, 0.7245, 0.7233, 0.718, 0.7295, 0.7259, 0.7194] / [0.7264, 0.7264, 0.7265, 0.7273, 0.7256, 0.7263, 0.7272], mean fold time: 0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:36,105] Trial 86 finished with value: 0.7234621279610975 and parameters: {'model__n_estimators': 700, 'model__learning_rate': 0.16, 'model__max_depth': 4, 'model__num_leaves': 152, 'model__min_gain_to_split': 10.0, 'model__min_data_in_leaf': 1400, 'model__lambda_l1': 15, 'model__lambda_l2': 95, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.6000000000000001, 'model__max_bin': 150}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00342 train_set_score:0.7251\n",
      "folds val/train: [0.7238, 0.7244, 0.7234, 0.7186, 0.7299, 0.7251, 0.7198] / [0.725, 0.725, 0.7251, 0.7259, 0.7241, 0.7249, 0.7254], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:38,484] Trial 87 finished with value: 0.7235689098969511 and parameters: {'model__n_estimators': 500, 'model__learning_rate': 0.21000000000000002, 'model__max_depth': 3, 'model__num_leaves': 176, 'model__min_gain_to_split': 12.0, 'model__min_data_in_leaf': 2100, 'model__lambda_l1': 10, 'model__lambda_l2': 105, 'model__bagging_fraction': 0.5, 'model__feature_fraction': 0.4, 'model__max_bin': 100}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00380 train_set_score:0.7263\n",
      "folds val/train: [0.7245, 0.7249, 0.7237, 0.7178, 0.7297, 0.7259, 0.7189] / [0.7263, 0.7262, 0.7263, 0.7272, 0.7253, 0.726, 0.7269], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:40,856] Trial 88 finished with value: 0.723631413409773 and parameters: {'model__n_estimators': 850, 'model__learning_rate': 0.29000000000000004, 'model__max_depth': 4, 'model__num_leaves': 160, 'model__min_gain_to_split': 13.5, 'model__min_data_in_leaf': 1500, 'model__lambda_l1': 0, 'model__lambda_l2': 100, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.5, 'model__max_bin': 125}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00353 train_set_score:0.7251\n",
      "folds val/train: [0.7236, 0.7246, 0.7234, 0.7186, 0.73, 0.7255, 0.7196] / [0.7252, 0.7251, 0.7252, 0.7259, 0.724, 0.725, 0.7257], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:43,143] Trial 89 finished with value: 0.7236238387146402 and parameters: {'model__n_estimators': 750, 'model__learning_rate': 0.26, 'model__max_depth': 4, 'model__num_leaves': 120, 'model__min_gain_to_split': 13.0, 'model__min_data_in_leaf': 1800, 'model__lambda_l1': 25, 'model__lambda_l2': 105, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.4, 'model__max_bin': 150}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7235, std_test_score:0.00357 train_set_score:0.7264\n",
      "folds val/train: [0.7239, 0.7246, 0.7231, 0.7182, 0.7298, 0.7253, 0.7194] / [0.7265, 0.7263, 0.7264, 0.7271, 0.7253, 0.7264, 0.7272], mean fold time: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:45,666] Trial 90 finished with value: 0.723492415258532 and parameters: {'model__n_estimators': 150, 'model__learning_rate': 0.23, 'model__max_depth': 3, 'model__num_leaves': 184, 'model__min_gain_to_split': 2.0, 'model__min_data_in_leaf': 2000, 'model__lambda_l1': 15, 'model__lambda_l2': 85, 'model__bagging_fraction': 0.4, 'model__feature_fraction': 0.5, 'model__max_bin': 175}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00354 train_set_score:0.7250\n",
      "folds val/train: [0.7236, 0.7244, 0.7234, 0.7187, 0.7301, 0.7254, 0.7194] / [0.725, 0.7248, 0.7249, 0.7258, 0.7239, 0.7247, 0.7256], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:47,974] Trial 91 finished with value: 0.7235689296793887 and parameters: {'model__n_estimators': 700, 'model__learning_rate': 0.25, 'model__max_depth': 4, 'model__num_leaves': 176, 'model__min_gain_to_split': 12.0, 'model__min_data_in_leaf': 2300, 'model__lambda_l1': 5, 'model__lambda_l2': 110, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.4, 'model__max_bin': 75}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7232, std_test_score:0.00369 train_set_score:0.7262\n",
      "folds val/train: [0.7234, 0.7247, 0.7231, 0.7178, 0.7294, 0.7255, 0.7188] / [0.7262, 0.7262, 0.7261, 0.7271, 0.7252, 0.726, 0.7269], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:50,389] Trial 92 finished with value: 0.7232462093129443 and parameters: {'model__n_estimators': 600, 'model__learning_rate': 0.27, 'model__max_depth': 4, 'model__num_leaves': 192, 'model__min_gain_to_split': 11.5, 'model__min_data_in_leaf': 2200, 'model__lambda_l1': 5, 'model__lambda_l2': 110, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.8, 'model__max_bin': 150}. Best is trial 64 with value: 0.7238869400023052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00372 train_set_score:0.7253\n",
      "folds val/train: [0.724, 0.7248, 0.7236, 0.7186, 0.7306, 0.7259, 0.7196] / [0.7253, 0.7252, 0.7254, 0.7261, 0.724, 0.7251, 0.7258], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:52,728] Trial 93 finished with value: 0.7238881734893879 and parameters: {'model__n_estimators': 800, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 8, 'model__num_leaves': 176, 'model__min_gain_to_split': 12.5, 'model__min_data_in_leaf': 1600, 'model__lambda_l1': 10, 'model__lambda_l2': 105, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7238, std_test_score:0.00365 train_set_score:0.7253\n",
      "folds val/train: [0.724, 0.7248, 0.7236, 0.7186, 0.7304, 0.7259, 0.7196] / [0.7253, 0.7252, 0.7253, 0.7261, 0.724, 0.7251, 0.7257], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:55,082] Trial 94 finished with value: 0.7238447300443738 and parameters: {'model__n_estimators': 800, 'model__learning_rate': 0.22, 'model__max_depth': 8, 'model__num_leaves': 224, 'model__min_gain_to_split': 12.5, 'model__min_data_in_leaf': 1600, 'model__lambda_l1': 10, 'model__lambda_l2': 100, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7238, std_test_score:0.00366 train_set_score:0.7253\n",
      "folds val/train: [0.724, 0.7247, 0.7235, 0.7186, 0.7304, 0.7258, 0.7196] / [0.7253, 0.7251, 0.7254, 0.7261, 0.7242, 0.725, 0.7257], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:57,443] Trial 95 finished with value: 0.7237957574809667 and parameters: {'model__n_estimators': 850, 'model__learning_rate': 0.22, 'model__max_depth': 8, 'model__num_leaves': 224, 'model__min_gain_to_split': 11.0, 'model__min_data_in_leaf': 1600, 'model__lambda_l1': 20, 'model__lambda_l2': 100, 'model__bagging_fraction': 0.5, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7235, std_test_score:0.00347 train_set_score:0.7250\n",
      "folds val/train: [0.7236, 0.7244, 0.7234, 0.7185, 0.7299, 0.7251, 0.7196] / [0.7249, 0.725, 0.725, 0.7259, 0.7238, 0.7249, 0.7257], mean fold time: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:02:59,884] Trial 96 finished with value: 0.7234987471236332 and parameters: {'model__n_estimators': 800, 'model__learning_rate': 0.19, 'model__max_depth': 8, 'model__num_leaves': 208, 'model__min_gain_to_split': 12.5, 'model__min_data_in_leaf': 1400, 'model__lambda_l1': 10, 'model__lambda_l2': 95, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 100}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7238, std_test_score:0.00369 train_set_score:0.7252\n",
      "folds val/train: [0.724, 0.7248, 0.7236, 0.7185, 0.7305, 0.7259, 0.7197] / [0.7253, 0.7251, 0.7253, 0.7261, 0.724, 0.7251, 0.7257], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:02,236] Trial 97 finished with value: 0.7238438963870556 and parameters: {'model__n_estimators': 750, 'model__learning_rate': 0.22, 'model__max_depth': 8, 'model__num_leaves': 240, 'model__min_gain_to_split': 11.0, 'model__min_data_in_leaf': 1700, 'model__lambda_l1': 15, 'model__lambda_l2': 105, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00358 train_set_score:0.7256\n",
      "folds val/train: [0.7239, 0.7248, 0.7234, 0.7185, 0.7301, 0.7255, 0.7195] / [0.7256, 0.7256, 0.7257, 0.7264, 0.7246, 0.7253, 0.7261], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:04,615] Trial 98 finished with value: 0.7236686616289821 and parameters: {'model__n_estimators': 850, 'model__learning_rate': 0.23, 'model__max_depth': 9, 'model__num_leaves': 232, 'model__min_gain_to_split': 10.5, 'model__min_data_in_leaf': 1000, 'model__lambda_l1': 10, 'model__lambda_l2': 90, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 400}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7233, std_test_score:0.00374 train_set_score:0.7261\n",
      "folds val/train: [0.7233, 0.7244, 0.723, 0.7179, 0.7302, 0.7253, 0.7193] / [0.7261, 0.726, 0.7259, 0.727, 0.7249, 0.7258, 0.7267], mean fold time: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:07,169] Trial 99 finished with value: 0.7233480888263631 and parameters: {'model__n_estimators': 800, 'model__learning_rate': 0.21000000000000002, 'model__max_depth': 8, 'model__num_leaves': 216, 'model__min_gain_to_split': 9.0, 'model__min_data_in_leaf': 1200, 'model__lambda_l1': 70, 'model__lambda_l2': 100, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.5, 'model__max_bin': 75}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7233, std_test_score:0.00357 train_set_score:0.7248\n",
      "folds val/train: [0.7232, 0.7244, 0.723, 0.7183, 0.7298, 0.7253, 0.7192] / [0.7249, 0.7249, 0.7249, 0.7256, 0.7235, 0.7247, 0.725], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:09,565] Trial 100 finished with value: 0.723334171378091 and parameters: {'model__n_estimators': 650, 'model__learning_rate': 0.2, 'model__max_depth': 9, 'model__num_leaves': 256, 'model__min_gain_to_split': 13.5, 'model__min_data_in_leaf': 1600, 'model__lambda_l1': 110, 'model__lambda_l2': 95, 'model__bagging_fraction': 0.5, 'model__feature_fraction': 0.4, 'model__max_bin': 150}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00369 train_set_score:0.7252\n",
      "folds val/train: [0.724, 0.7248, 0.7235, 0.7186, 0.7305, 0.7259, 0.7197] / [0.7253, 0.7251, 0.7254, 0.7261, 0.724, 0.7251, 0.7257], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:11,956] Trial 101 finished with value: 0.7238707781733537 and parameters: {'model__n_estimators': 750, 'model__learning_rate': 0.22, 'model__max_depth': 8, 'model__num_leaves': 224, 'model__min_gain_to_split': 11.5, 'model__min_data_in_leaf': 1700, 'model__lambda_l1': 15, 'model__lambda_l2': 105, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7238, std_test_score:0.00369 train_set_score:0.7253\n",
      "folds val/train: [0.724, 0.7247, 0.7236, 0.7185, 0.7305, 0.7258, 0.7196] / [0.7253, 0.7251, 0.7254, 0.7261, 0.7242, 0.7251, 0.726], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:14,284] Trial 102 finished with value: 0.7238010523634463 and parameters: {'model__n_estimators': 750, 'model__learning_rate': 0.23, 'model__max_depth': 8, 'model__num_leaves': 240, 'model__min_gain_to_split': 11.5, 'model__min_data_in_leaf': 1500, 'model__lambda_l1': 20, 'model__lambda_l2': 105, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7235, std_test_score:0.00352 train_set_score:0.7250\n",
      "folds val/train: [0.7238, 0.7244, 0.7234, 0.7183, 0.73, 0.7251, 0.7197] / [0.725, 0.725, 0.7251, 0.7259, 0.7238, 0.7249, 0.7255], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:16,803] Trial 103 finished with value: 0.7235247657644909 and parameters: {'model__n_estimators': 750, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 9, 'model__num_leaves': 208, 'model__min_gain_to_split': 12.5, 'model__min_data_in_leaf': 1800, 'model__lambda_l1': 15, 'model__lambda_l2': 105, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 100}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00350 train_set_score:0.7251\n",
      "folds val/train: [0.7233, 0.7247, 0.7233, 0.7187, 0.73, 0.7255, 0.7197] / [0.7246, 0.7252, 0.7253, 0.726, 0.7239, 0.725, 0.7257], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:19,085] Trial 104 finished with value: 0.7235769876116782 and parameters: {'model__n_estimators': 800, 'model__learning_rate': 0.22, 'model__max_depth': 7, 'model__num_leaves': 224, 'model__min_gain_to_split': 12.0, 'model__min_data_in_leaf': 1700, 'model__lambda_l1': 10, 'model__lambda_l2': 100, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 150}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7235, std_test_score:0.00346 train_set_score:0.7250\n",
      "folds val/train: [0.7238, 0.7243, 0.7234, 0.7185, 0.7299, 0.7251, 0.7198] / [0.725, 0.725, 0.7251, 0.7259, 0.7237, 0.7249, 0.7256], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:21,375] Trial 105 finished with value: 0.7235385476225756 and parameters: {'model__n_estimators': 900, 'model__learning_rate': 0.25, 'model__max_depth': 8, 'model__num_leaves': 200, 'model__min_gain_to_split': 13.0, 'model__min_data_in_leaf': 1900, 'model__lambda_l1': 0, 'model__lambda_l2': 110, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 100}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7238, std_test_score:0.00369 train_set_score:0.7252\n",
      "folds val/train: [0.7239, 0.7248, 0.7236, 0.7185, 0.7305, 0.7257, 0.7197] / [0.7252, 0.7252, 0.7252, 0.726, 0.7239, 0.725, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:23,710] Trial 106 finished with value: 0.7238081470068413 and parameters: {'model__n_estimators': 650, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 8, 'model__num_leaves': 192, 'model__min_gain_to_split': 14.0, 'model__min_data_in_leaf': 1600, 'model__lambda_l1': 25, 'model__lambda_l2': 95, 'model__bagging_fraction': 0.5, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7231, std_test_score:0.00369 train_set_score:0.7279\n",
      "folds val/train: [0.7233, 0.7241, 0.7229, 0.718, 0.7297, 0.7253, 0.7187] / [0.7278, 0.7279, 0.728, 0.7287, 0.7269, 0.7275, 0.7286], mean fold time: 0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:26,330] Trial 107 finished with value: 0.7231430431743641 and parameters: {'model__n_estimators': 700, 'model__learning_rate': 0.26, 'model__max_depth': 7, 'model__num_leaves': 128, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 1500, 'model__lambda_l1': 5, 'model__lambda_l2': 90, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.5, 'model__max_bin': 175}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7229, std_test_score:0.00361 train_set_score:0.7245\n",
      "folds val/train: [0.7226, 0.7238, 0.7215, 0.7179, 0.7299, 0.7247, 0.7195] / [0.7245, 0.7243, 0.7246, 0.7253, 0.7234, 0.7241, 0.7254], mean fold time: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:28,502] Trial 108 finished with value: 0.7228556702432846 and parameters: {'model__n_estimators': 850, 'model__learning_rate': 0.05, 'model__max_depth': 9, 'model__num_leaves': 232, 'model__min_gain_to_split': 10.5, 'model__min_data_in_leaf': 400, 'model__lambda_l1': 10, 'model__lambda_l2': 80, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 375}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00371 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7247, 0.7235, 0.7186, 0.7307, 0.726, 0.7197] / [0.7254, 0.7253, 0.7256, 0.7262, 0.7243, 0.7252, 0.7261], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:30,806] Trial 109 finished with value: 0.723885389715335 and parameters: {'model__n_estimators': 450, 'model__learning_rate': 0.27, 'model__max_depth': 8, 'model__num_leaves': 248, 'model__min_gain_to_split': 10.0, 'model__min_data_in_leaf': 1400, 'model__lambda_l1': 0, 'model__lambda_l2': 100, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00356 train_set_score:0.7258\n",
      "folds val/train: [0.7239, 0.7246, 0.7229, 0.7187, 0.7302, 0.7254, 0.7196] / [0.7259, 0.7258, 0.726, 0.7266, 0.7246, 0.7256, 0.7263], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:33,170] Trial 110 finished with value: 0.7236248701064721 and parameters: {'model__n_estimators': 400, 'model__learning_rate': 0.27, 'model__max_depth': 7, 'model__num_leaves': 240, 'model__min_gain_to_split': 10.0, 'model__min_data_in_leaf': 1300, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 0.8, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 475}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7238, std_test_score:0.00369 train_set_score:0.7253\n",
      "folds val/train: [0.724, 0.7248, 0.7235, 0.7185, 0.7305, 0.7259, 0.7196] / [0.7254, 0.7252, 0.7254, 0.7261, 0.7241, 0.7251, 0.7258], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:35,470] Trial 111 finished with value: 0.7238292039535024 and parameters: {'model__n_estimators': 800, 'model__learning_rate': 0.25, 'model__max_depth': 8, 'model__num_leaves': 256, 'model__min_gain_to_split': 11.5, 'model__min_data_in_leaf': 1400, 'model__lambda_l1': 5, 'model__lambda_l2': 100, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00351 train_set_score:0.7252\n",
      "folds val/train: [0.7238, 0.7247, 0.7233, 0.7188, 0.73, 0.7256, 0.7196] / [0.7253, 0.7252, 0.7254, 0.726, 0.7239, 0.725, 0.7256], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:37,846] Trial 112 finished with value: 0.7236634622264965 and parameters: {'model__n_estimators': 750, 'model__learning_rate': 0.21000000000000002, 'model__max_depth': 8, 'model__num_leaves': 216, 'model__min_gain_to_split': 12.0, 'model__min_data_in_leaf': 1700, 'model__lambda_l1': 0, 'model__lambda_l2': 110, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.4, 'model__max_bin': 150}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7235, std_test_score:0.00352 train_set_score:0.7251\n",
      "folds val/train: [0.7238, 0.7242, 0.7235, 0.7185, 0.73, 0.7251, 0.7195] / [0.7251, 0.7249, 0.7251, 0.7259, 0.7239, 0.7249, 0.7256], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:40,150] Trial 113 finished with value: 0.7235129332238072 and parameters: {'model__n_estimators': 450, 'model__learning_rate': 0.27, 'model__max_depth': 9, 'model__num_leaves': 248, 'model__min_gain_to_split': 11.0, 'model__min_data_in_leaf': 1800, 'model__lambda_l1': 10, 'model__lambda_l2': 100, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 100}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7234, std_test_score:0.00379 train_set_score:0.7265\n",
      "folds val/train: [0.7237, 0.7245, 0.723, 0.7179, 0.7302, 0.7253, 0.719] / [0.7264, 0.7264, 0.7265, 0.7274, 0.7253, 0.7262, 0.7272], mean fold time: 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:42,851] Trial 114 finished with value: 0.7233640844066517 and parameters: {'model__n_estimators': 450, 'model__learning_rate': 0.18000000000000002, 'model__max_depth': 8, 'model__num_leaves': 184, 'model__min_gain_to_split': 12.5, 'model__min_data_in_leaf': 1600, 'model__lambda_l1': 15, 'model__lambda_l2': 95, 'model__bagging_fraction': 0.8, 'model__feature_fraction': 0.5, 'model__max_bin': 75}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7238, std_test_score:0.00361 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7247, 0.7235, 0.7187, 0.7304, 0.7259, 0.7197] / [0.7254, 0.7253, 0.7254, 0.7261, 0.7243, 0.7251, 0.7261], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:45,220] Trial 115 finished with value: 0.7238440691072416 and parameters: {'model__n_estimators': 800, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 248, 'model__min_gain_to_split': 9.5, 'model__min_data_in_leaf': 1200, 'model__lambda_l1': 5, 'model__lambda_l2': 105, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7238, std_test_score:0.00368 train_set_score:0.7253\n",
      "folds val/train: [0.7239, 0.7247, 0.7235, 0.7185, 0.7305, 0.7259, 0.7198] / [0.7253, 0.7252, 0.7255, 0.7262, 0.7235, 0.7251, 0.7261], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:47,566] Trial 116 finished with value: 0.7238216590885449 and parameters: {'model__n_estimators': 400, 'model__learning_rate': 0.26, 'model__max_depth': 8, 'model__num_leaves': 248, 'model__min_gain_to_split': 8.5, 'model__min_data_in_leaf': 1400, 'model__lambda_l1': 20, 'model__lambda_l2': 50, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00346 train_set_score:0.7251\n",
      "folds val/train: [0.7238, 0.7244, 0.7234, 0.7185, 0.73, 0.7251, 0.7198] / [0.725, 0.725, 0.7251, 0.7259, 0.724, 0.7249, 0.7257], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:49,792] Trial 117 finished with value: 0.7235786605771052 and parameters: {'model__n_estimators': 700, 'model__learning_rate': 0.29000000000000004, 'model__max_depth': 7, 'model__num_leaves': 144, 'model__min_gain_to_split': 10.5, 'model__min_data_in_leaf': 2100, 'model__lambda_l1': 0, 'model__lambda_l2': 105, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 100}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7235, std_test_score:0.00382 train_set_score:0.7260\n",
      "folds val/train: [0.7243, 0.7245, 0.7233, 0.7178, 0.7302, 0.7252, 0.719] / [0.7258, 0.7258, 0.726, 0.7268, 0.7249, 0.7258, 0.7267], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:52,186] Trial 118 finished with value: 0.723475175375283 and parameters: {'model__n_estimators': 850, 'model__learning_rate': 0.23, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 13.0, 'model__min_data_in_leaf': 1900, 'model__lambda_l1': 5, 'model__lambda_l2': 100, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.5, 'model__max_bin': 175}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7234, std_test_score:0.00352 train_set_score:0.7250\n",
      "folds val/train: [0.7233, 0.7245, 0.723, 0.7185, 0.7299, 0.7254, 0.7195] / [0.7251, 0.725, 0.7247, 0.7259, 0.7238, 0.7249, 0.7258], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:54,416] Trial 119 finished with value: 0.7234358552639505 and parameters: {'model__n_estimators': 750, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 104, 'model__min_gain_to_split': 11.5, 'model__min_data_in_leaf': 1500, 'model__lambda_l1': 50, 'model__lambda_l2': 105, 'model__bagging_fraction': 0.6000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 150}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7235, std_test_score:0.00348 train_set_score:0.7251\n",
      "folds val/train: [0.7237, 0.7243, 0.7233, 0.7184, 0.7298, 0.7252, 0.7196] / [0.725, 0.725, 0.7251, 0.7259, 0.7241, 0.7249, 0.7258], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:56,775] Trial 120 finished with value: 0.7234807478234151 and parameters: {'model__n_estimators': 700, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 8, 'model__num_leaves': 168, 'model__min_gain_to_split': 10.0, 'model__min_data_in_leaf': 1300, 'model__lambda_l1': 10, 'model__lambda_l2': 110, 'model__bagging_fraction': 0.8, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 100}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00345 train_set_score:0.7252\n",
      "folds val/train: [0.7238, 0.7245, 0.7234, 0.7189, 0.73, 0.7255, 0.7196] / [0.7252, 0.7251, 0.7253, 0.726, 0.7241, 0.7251, 0.7258], mean fold time: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:03:58,979] Trial 121 finished with value: 0.7236687469585865 and parameters: {'model__n_estimators': 800, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 240, 'model__min_gain_to_split': 11.0, 'model__min_data_in_leaf': 1200, 'model__lambda_l1': 5, 'model__lambda_l2': 100, 'model__bagging_fraction': 0.7, 'model__feature_fraction': 0.4, 'model__max_bin': 150}. Best is trial 93 with value: 0.7238881734893879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00362 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7247, 0.7236, 0.7188, 0.7305, 0.7259, 0.7198] / [0.7254, 0.7252, 0.7254, 0.7261, 0.7242, 0.7251, 0.7261], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:01,259] Trial 122 finished with value: 0.7239030886519192 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 256, 'model__min_gain_to_split': 9.5, 'model__min_data_in_leaf': 1000, 'model__lambda_l1': 0, 'model__lambda_l2': 95, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 122 with value: 0.7239030886519192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7238, std_test_score:0.00370 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7247, 0.7234, 0.7186, 0.7306, 0.7259, 0.7197] / [0.7254, 0.7251, 0.7256, 0.7262, 0.7243, 0.7252, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:03,524] Trial 123 finished with value: 0.723848463229252 and parameters: {'model__n_estimators': 350, 'model__learning_rate': 0.27, 'model__max_depth': 11, 'model__num_leaves': 248, 'model__min_gain_to_split': 10.0, 'model__min_data_in_leaf': 1000, 'model__lambda_l1': 0, 'model__lambda_l2': 95, 'model__bagging_fraction': 0.9000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 122 with value: 0.7239030886519192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00351 train_set_score:0.7253\n",
      "folds val/train: [0.7238, 0.7245, 0.7232, 0.7187, 0.73, 0.7255, 0.7196] / [0.7254, 0.7253, 0.7255, 0.7261, 0.724, 0.7252, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:05,809] Trial 124 finished with value: 0.7236143433429204 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.27, 'model__max_depth': 11, 'model__num_leaves': 256, 'model__min_gain_to_split': 10.0, 'model__min_data_in_leaf': 900, 'model__lambda_l1': 0, 'model__lambda_l2': 90, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 150}. Best is trial 122 with value: 0.7239030886519192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00363 train_set_score:0.7253\n",
      "folds val/train: [0.7242, 0.7247, 0.7236, 0.7187, 0.7305, 0.726, 0.7198] / [0.7254, 0.7253, 0.7254, 0.7262, 0.7242, 0.7251, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:08,025] Trial 125 finished with value: 0.723931080123364 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 256, 'model__min_gain_to_split': 9.5, 'model__min_data_in_leaf': 700, 'model__lambda_l1': 0, 'model__lambda_l2': 95, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 125 with value: 0.723931080123364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00364 train_set_score:0.7254\n",
      "folds val/train: [0.7242, 0.7247, 0.7236, 0.7187, 0.7304, 0.7259, 0.7197] / [0.7254, 0.7253, 0.7254, 0.7262, 0.7242, 0.7251, 0.7261], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:10,225] Trial 126 finished with value: 0.7238771618951632 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.29000000000000004, 'model__max_depth': 3, 'model__num_leaves': 256, 'model__min_gain_to_split': 9.0, 'model__min_data_in_leaf': 600, 'model__lambda_l1': 0, 'model__lambda_l2': 95, 'model__bagging_fraction': 0.9000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 125 with value: 0.723931080123364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00342 train_set_score:0.7251\n",
      "folds val/train: [0.7239, 0.7243, 0.7235, 0.7187, 0.73, 0.7252, 0.7199] / [0.7251, 0.7249, 0.7251, 0.7259, 0.7242, 0.7249, 0.7257], mean fold time: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:12,405] Trial 127 finished with value: 0.723620148592944 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.29000000000000004, 'model__max_depth': 3, 'model__num_leaves': 248, 'model__min_gain_to_split': 9.0, 'model__min_data_in_leaf': 600, 'model__lambda_l1': 0, 'model__lambda_l2': 85, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 100}. Best is trial 125 with value: 0.723931080123364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7233, std_test_score:0.00368 train_set_score:0.7258\n",
      "folds val/train: [0.724, 0.7241, 0.7226, 0.7179, 0.7296, 0.7257, 0.719] / [0.7257, 0.7258, 0.7257, 0.7267, 0.7247, 0.7255, 0.7265], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:14,676] Trial 128 finished with value: 0.7233009464455774 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.3, 'model__max_depth': 3, 'model__num_leaves': 120, 'model__min_gain_to_split': 9.5, 'model__min_data_in_leaf': 700, 'model__lambda_l1': 5, 'model__lambda_l2': 95, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.5, 'model__max_bin': 125}. Best is trial 125 with value: 0.723931080123364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00363 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7247, 0.7236, 0.7187, 0.7305, 0.7259, 0.7198] / [0.7254, 0.7253, 0.7254, 0.7262, 0.7242, 0.7252, 0.7261], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:16,870] Trial 129 finished with value: 0.7238917173282259 and parameters: {'model__n_estimators': 50, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 256, 'model__min_gain_to_split': 8.0, 'model__min_data_in_leaf': 500, 'model__lambda_l1': 0, 'model__lambda_l2': 90, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 125 with value: 0.723931080123364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00346 train_set_score:0.7251\n",
      "folds val/train: [0.7239, 0.7243, 0.7235, 0.7186, 0.7299, 0.7252, 0.7197] / [0.7251, 0.725, 0.7251, 0.7259, 0.7237, 0.725, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:19,170] Trial 130 finished with value: 0.7235791138629298 and parameters: {'model__n_estimators': 50, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 256, 'model__min_gain_to_split': 8.5, 'model__min_data_in_leaf': 400, 'model__lambda_l1': 0, 'model__lambda_l2': 90, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 100}. Best is trial 125 with value: 0.723931080123364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00362 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7247, 0.7237, 0.7187, 0.7304, 0.7259, 0.7197] / [0.7254, 0.7253, 0.7255, 0.7261, 0.7241, 0.7251, 0.7261], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:21,400] Trial 131 finished with value: 0.7238953898963087 and parameters: {'model__n_estimators': 150, 'model__learning_rate': 0.29000000000000004, 'model__max_depth': 3, 'model__num_leaves': 256, 'model__min_gain_to_split': 8.0, 'model__min_data_in_leaf': 500, 'model__lambda_l1': 0, 'model__lambda_l2': 95, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 125 with value: 0.723931080123364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00362 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7247, 0.7237, 0.7187, 0.7304, 0.7259, 0.7197] / [0.7254, 0.7253, 0.7255, 0.7261, 0.7241, 0.7251, 0.7261], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:23,645] Trial 132 finished with value: 0.7238953898963087 and parameters: {'model__n_estimators': 100, 'model__learning_rate': 0.29000000000000004, 'model__max_depth': 3, 'model__num_leaves': 256, 'model__min_gain_to_split': 8.0, 'model__min_data_in_leaf': 500, 'model__lambda_l1': 0, 'model__lambda_l2': 95, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 125 with value: 0.723931080123364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00361 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7247, 0.7236, 0.7187, 0.7304, 0.7259, 0.7198] / [0.7254, 0.7253, 0.7254, 0.7261, 0.7242, 0.7252, 0.7261], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:25,912] Trial 133 finished with value: 0.7238734761145377 and parameters: {'model__n_estimators': 100, 'model__learning_rate': 0.29000000000000004, 'model__max_depth': 3, 'model__num_leaves': 256, 'model__min_gain_to_split': 8.0, 'model__min_data_in_leaf': 500, 'model__lambda_l1': 0, 'model__lambda_l2': 90, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 125 with value: 0.723931080123364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00351 train_set_score:0.7253\n",
      "folds val/train: [0.7239, 0.7246, 0.7236, 0.7188, 0.7301, 0.7255, 0.7195] / [0.7253, 0.7252, 0.7254, 0.726, 0.7242, 0.7251, 0.726], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:28,141] Trial 134 finished with value: 0.7237266670838816 and parameters: {'model__n_estimators': 100, 'model__learning_rate': 0.29000000000000004, 'model__max_depth': 3, 'model__num_leaves': 256, 'model__min_gain_to_split': 8.0, 'model__min_data_in_leaf': 400, 'model__lambda_l1': 0, 'model__lambda_l2': 85, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 150}. Best is trial 125 with value: 0.723931080123364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00361 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7247, 0.7236, 0.7187, 0.7304, 0.7259, 0.7198] / [0.7254, 0.7253, 0.7255, 0.7261, 0.7244, 0.7252, 0.7261], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:30,383] Trial 135 finished with value: 0.7238844060520144 and parameters: {'model__n_estimators': 150, 'model__learning_rate': 0.29000000000000004, 'model__max_depth': 3, 'model__num_leaves': 240, 'model__min_gain_to_split': 7.0, 'model__min_data_in_leaf': 500, 'model__lambda_l1': 0, 'model__lambda_l2': 90, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 125 with value: 0.723931080123364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00344 train_set_score:0.7251\n",
      "folds val/train: [0.7239, 0.7244, 0.7235, 0.7186, 0.73, 0.7252, 0.7198] / [0.7251, 0.7251, 0.7251, 0.726, 0.7238, 0.725, 0.7257], mean fold time: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:32,590] Trial 136 finished with value: 0.7236114625693554 and parameters: {'model__n_estimators': 100, 'model__learning_rate': 0.3, 'model__max_depth': 3, 'model__num_leaves': 248, 'model__min_gain_to_split': 7.0, 'model__min_data_in_leaf': 500, 'model__lambda_l1': 0, 'model__lambda_l2': 90, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 100}. Best is trial 125 with value: 0.723931080123364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7233, std_test_score:0.00365 train_set_score:0.7260\n",
      "folds val/train: [0.7243, 0.7239, 0.7228, 0.718, 0.7295, 0.7258, 0.7191] / [0.7261, 0.726, 0.7259, 0.7269, 0.7249, 0.7256, 0.7267], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:34,874] Trial 137 finished with value: 0.7233375124263868 and parameters: {'model__n_estimators': 100, 'model__learning_rate': 0.29000000000000004, 'model__max_depth': 3, 'model__num_leaves': 256, 'model__min_gain_to_split': 7.5, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 0, 'model__lambda_l2': 90, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.5, 'model__max_bin': 125}. Best is trial 125 with value: 0.723931080123364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00352 train_set_score:0.7250\n",
      "folds val/train: [0.7237, 0.7244, 0.7234, 0.7187, 0.73, 0.7255, 0.7194] / [0.725, 0.7249, 0.7249, 0.7259, 0.7238, 0.7247, 0.7256], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:37,192] Trial 138 finished with value: 0.7235935599498056 and parameters: {'model__n_estimators': 150, 'model__learning_rate': 0.29000000000000004, 'model__max_depth': 3, 'model__num_leaves': 248, 'model__min_gain_to_split': 7.0, 'model__min_data_in_leaf': 700, 'model__lambda_l1': 5, 'model__lambda_l2': 80, 'model__bagging_fraction': 0.9000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 75}. Best is trial 125 with value: 0.723931080123364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00351 train_set_score:0.7253\n",
      "folds val/train: [0.7239, 0.7246, 0.7236, 0.7188, 0.7301, 0.7255, 0.7195] / [0.7253, 0.7251, 0.7253, 0.726, 0.7242, 0.7251, 0.726], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:39,440] Trial 139 finished with value: 0.7236864268453485 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.3, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 8.0, 'model__min_data_in_leaf': 500, 'model__lambda_l1': 0, 'model__lambda_l2': 95, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 150}. Best is trial 125 with value: 0.723931080123364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00363 train_set_score:0.7254\n",
      "folds val/train: [0.7242, 0.7248, 0.7236, 0.7187, 0.7305, 0.7259, 0.7198] / [0.7254, 0.7253, 0.7254, 0.7262, 0.7242, 0.7252, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:41,730] Trial 140 finished with value: 0.7239349274853204 and parameters: {'model__n_estimators': 50, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 240, 'model__min_gain_to_split': 7.0, 'model__min_data_in_leaf': 500, 'model__lambda_l1': 5, 'model__lambda_l2': 75, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00363 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7248, 0.7236, 0.7187, 0.7306, 0.7259, 0.7199] / [0.7254, 0.7253, 0.7254, 0.7262, 0.7241, 0.7251, 0.7259], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:44,092] Trial 141 finished with value: 0.7239303784632046 and parameters: {'model__n_estimators': 50, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 240, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 500, 'model__lambda_l1': 5, 'model__lambda_l2': 75, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00340 train_set_score:0.7251\n",
      "folds val/train: [0.7239, 0.7243, 0.7234, 0.7187, 0.7299, 0.7251, 0.7197] / [0.7251, 0.725, 0.7251, 0.7259, 0.7242, 0.7249, 0.7256], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:46,390] Trial 142 finished with value: 0.7235636900680591 and parameters: {'model__n_estimators': 50, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 240, 'model__min_gain_to_split': 7.0, 'model__min_data_in_leaf': 500, 'model__lambda_l1': 5, 'model__lambda_l2': 85, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 100}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00361 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7246, 0.7237, 0.7188, 0.7306, 0.7259, 0.7198] / [0.7255, 0.7254, 0.7255, 0.7262, 0.7242, 0.7252, 0.726], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:48,683] Trial 143 finished with value: 0.723927820151293 and parameters: {'model__n_estimators': 150, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 240, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 300, 'model__lambda_l1': 0, 'model__lambda_l2': 85, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00363 train_set_score:0.7254\n",
      "folds val/train: [0.7242, 0.7246, 0.7235, 0.7187, 0.7305, 0.7259, 0.7198] / [0.7254, 0.7253, 0.7255, 0.7262, 0.7239, 0.7252, 0.7262], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:50,992] Trial 144 finished with value: 0.7238938865209638 and parameters: {'model__n_estimators': 150, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 240, 'model__min_gain_to_split': 5.5, 'model__min_data_in_leaf': 300, 'model__lambda_l1': 5, 'model__lambda_l2': 70, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00347 train_set_score:0.7252\n",
      "folds val/train: [0.7239, 0.7246, 0.7234, 0.7188, 0.7299, 0.7255, 0.7195] / [0.7254, 0.7252, 0.7252, 0.7262, 0.7234, 0.7251, 0.726], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:53,352] Trial 145 finished with value: 0.7236771987317481 and parameters: {'model__n_estimators': 150, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 240, 'model__min_gain_to_split': 5.5, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 0, 'model__lambda_l2': 70, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 150}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00343 train_set_score:0.7251\n",
      "folds val/train: [0.7239, 0.7243, 0.7234, 0.7187, 0.7299, 0.7252, 0.7197] / [0.7251, 0.7251, 0.7252, 0.7259, 0.7239, 0.7249, 0.7256], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:55,637] Trial 146 finished with value: 0.7235832190480416 and parameters: {'model__n_estimators': 50, 'model__learning_rate': 0.27, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 300, 'model__lambda_l1': 5, 'model__lambda_l2': 75, 'model__bagging_fraction': 0.9000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 100}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00360 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7246, 0.7236, 0.7188, 0.7305, 0.7259, 0.7198] / [0.7254, 0.7253, 0.7255, 0.7262, 0.7242, 0.7252, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:04:57,918] Trial 147 finished with value: 0.723909594752433 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 240, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 5, 'model__lambda_l2': 75, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7232, std_test_score:0.00351 train_set_score:0.7260\n",
      "folds val/train: [0.724, 0.7239, 0.723, 0.7183, 0.7295, 0.725, 0.719] / [0.7261, 0.7259, 0.726, 0.7267, 0.725, 0.7258, 0.7267], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:00,330] Trial 148 finished with value: 0.7232306135525378 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.27, 'model__max_depth': 3, 'model__num_leaves': 240, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 5, 'model__lambda_l2': 75, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.5, 'model__max_bin': 150}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00362 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7247, 0.7235, 0.7188, 0.7305, 0.7259, 0.7198] / [0.7255, 0.7253, 0.7255, 0.7263, 0.724, 0.7252, 0.7261], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:02,597] Trial 149 finished with value: 0.7239020069426013 and parameters: {'model__n_estimators': 150, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 248, 'model__min_gain_to_split': 4.5, 'model__min_data_in_leaf': 300, 'model__lambda_l1': 5, 'model__lambda_l2': 70, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00348 train_set_score:0.7253\n",
      "folds val/train: [0.7239, 0.7245, 0.7235, 0.7189, 0.73, 0.7255, 0.7195] / [0.7254, 0.7251, 0.7252, 0.7262, 0.7241, 0.7251, 0.7258], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:04,861] Trial 150 finished with value: 0.7237018351245854 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 248, 'model__min_gain_to_split': 5.0, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 5, 'model__lambda_l2': 75, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 150}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00364 train_set_score:0.7254\n",
      "folds val/train: [0.7242, 0.7248, 0.7236, 0.7186, 0.7305, 0.7259, 0.7199] / [0.7254, 0.7253, 0.7254, 0.7262, 0.7242, 0.7252, 0.7259], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:07,212] Trial 151 finished with value: 0.723916939046771 and parameters: {'model__n_estimators': 150, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 240, 'model__min_gain_to_split': 5.5, 'model__min_data_in_leaf': 300, 'model__lambda_l1': 5, 'model__lambda_l2': 75, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00360 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7246, 0.7235, 0.7188, 0.7305, 0.7259, 0.7198] / [0.7255, 0.7254, 0.7255, 0.7262, 0.7242, 0.7252, 0.7259], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:09,587] Trial 152 finished with value: 0.7238882230311315 and parameters: {'model__n_estimators': 150, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 240, 'model__min_gain_to_split': 4.0, 'model__min_data_in_leaf': 300, 'model__lambda_l1': 0, 'model__lambda_l2': 65, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00343 train_set_score:0.7252\n",
      "folds val/train: [0.724, 0.7243, 0.7234, 0.7188, 0.7299, 0.7252, 0.7196] / [0.7252, 0.7252, 0.7252, 0.726, 0.724, 0.725, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:11,869] Trial 153 finished with value: 0.7235872369341887 and parameters: {'model__n_estimators': 150, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 4.0, 'model__min_data_in_leaf': 300, 'model__lambda_l1': 0, 'model__lambda_l2': 65, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 100}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00363 train_set_score:0.7254\n",
      "folds val/train: [0.7242, 0.7246, 0.7235, 0.7187, 0.7305, 0.7259, 0.7198] / [0.7254, 0.7253, 0.7255, 0.7262, 0.7239, 0.7252, 0.7262], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:14,207] Trial 154 finished with value: 0.7238938865209638 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 248, 'model__min_gain_to_split': 5.5, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 5, 'model__lambda_l2': 70, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7233, std_test_score:0.00368 train_set_score:0.7256\n",
      "folds val/train: [0.7238, 0.7245, 0.7228, 0.7178, 0.7296, 0.7257, 0.7191] / [0.7256, 0.7254, 0.7256, 0.7266, 0.7246, 0.7253, 0.7263], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:16,533] Trial 155 finished with value: 0.7233408359627614 and parameters: {'model__n_estimators': 150, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 240, 'model__min_gain_to_split': 5.5, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 85, 'model__lambda_l2': 70, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.7, 'model__max_bin': 125}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00343 train_set_score:0.7251\n",
      "folds val/train: [0.7238, 0.7243, 0.7233, 0.7187, 0.73, 0.7252, 0.7198] / [0.7251, 0.7251, 0.7252, 0.7259, 0.724, 0.7249, 0.7257], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:18,821] Trial 156 finished with value: 0.7235699170732991 and parameters: {'model__n_estimators': 100, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 5.0, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 10, 'model__lambda_l2': 70, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 100}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7233, std_test_score:0.00353 train_set_score:0.7248\n",
      "folds val/train: [0.7225, 0.7245, 0.7233, 0.7183, 0.7296, 0.7254, 0.7194] / [0.7242, 0.725, 0.7251, 0.7253, 0.7239, 0.7246, 0.7252], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:21,177] Trial 157 finished with value: 0.7232906459719283 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.09, 'model__max_depth': 3, 'model__num_leaves': 248, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 300, 'model__lambda_l1': 5, 'model__lambda_l2': 65, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 150}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00361 train_set_score:0.7254\n",
      "folds val/train: [0.7242, 0.7247, 0.7236, 0.7188, 0.7305, 0.726, 0.7198] / [0.7255, 0.7253, 0.7255, 0.7262, 0.7239, 0.7252, 0.7261], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:23,475] Trial 158 finished with value: 0.7239229303388101 and parameters: {'model__n_estimators': 50, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 256, 'model__min_gain_to_split': 3.5, 'model__min_data_in_leaf': 300, 'model__lambda_l1': 10, 'model__lambda_l2': 75, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7238, std_test_score:0.00351 train_set_score:0.7254\n",
      "folds val/train: [0.7237, 0.7249, 0.7236, 0.7189, 0.7301, 0.7256, 0.7196] / [0.7256, 0.7254, 0.7254, 0.7263, 0.724, 0.7253, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:25,741] Trial 159 finished with value: 0.7237530857919212 and parameters: {'model__n_estimators': 50, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 248, 'model__min_gain_to_split': 3.0, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 5, 'model__lambda_l2': 75, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 175}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00360 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7247, 0.7235, 0.7188, 0.7304, 0.7259, 0.7198] / [0.7254, 0.7253, 0.7255, 0.7262, 0.7242, 0.7252, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:28,049] Trial 160 finished with value: 0.7238840873658093 and parameters: {'model__n_estimators': 100, 'model__learning_rate': 0.27, 'model__max_depth': 3, 'model__num_leaves': 256, 'model__min_gain_to_split': 4.0, 'model__min_data_in_leaf': 400, 'model__lambda_l1': 10, 'model__lambda_l2': 70, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 140 with value: 0.7239349274853204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00362 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7247, 0.7235, 0.7188, 0.7305, 0.726, 0.7199] / [0.7254, 0.7253, 0.7254, 0.7262, 0.7242, 0.7252, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:30,338] Trial 161 finished with value: 0.7239376786470416 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 240, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 5, 'model__lambda_l2': 65, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00337 train_set_score:0.7251\n",
      "folds val/train: [0.7239, 0.7243, 0.7234, 0.7188, 0.7298, 0.7251, 0.7197] / [0.7251, 0.7251, 0.7251, 0.726, 0.7241, 0.7249, 0.7256], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:32,657] Trial 162 finished with value: 0.7235724635391867 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 240, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 5, 'model__lambda_l2': 80, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 100}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00362 train_set_score:0.7254\n",
      "folds val/train: [0.7242, 0.7246, 0.7236, 0.7186, 0.7305, 0.7259, 0.7199] / [0.7254, 0.7253, 0.7255, 0.7262, 0.7239, 0.7252, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:34,910] Trial 163 finished with value: 0.723894374102689 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 256, 'model__min_gain_to_split': 5.5, 'model__min_data_in_leaf': 300, 'model__lambda_l1': 5, 'model__lambda_l2': 65, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00348 train_set_score:0.7253\n",
      "folds val/train: [0.7239, 0.7246, 0.7233, 0.7188, 0.73, 0.7255, 0.7196] / [0.7254, 0.7251, 0.7254, 0.7261, 0.724, 0.7251, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:37,185] Trial 164 finished with value: 0.7236743476613146 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.3, 'model__max_depth': 3, 'model__num_leaves': 256, 'model__min_gain_to_split': 5.5, 'model__min_data_in_leaf': 300, 'model__lambda_l1': 0, 'model__lambda_l2': 65, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 150}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00359 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7247, 0.7235, 0.7189, 0.7305, 0.7259, 0.7199] / [0.7254, 0.7254, 0.7255, 0.7261, 0.724, 0.7252, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:39,467] Trial 165 finished with value: 0.7239167292458302 and parameters: {'model__n_estimators': 150, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 248, 'model__min_gain_to_split': 4.5, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 5, 'model__lambda_l2': 60, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00359 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7246, 0.7235, 0.7189, 0.7305, 0.7259, 0.7197] / [0.7255, 0.7254, 0.7256, 0.7261, 0.724, 0.7252, 0.7262], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:41,728] Trial 166 finished with value: 0.7238832863437005 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.29000000000000004, 'model__max_depth': 3, 'model__num_leaves': 256, 'model__min_gain_to_split': 4.5, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 5, 'model__lambda_l2': 60, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00342 train_set_score:0.7251\n",
      "folds val/train: [0.7239, 0.7243, 0.7234, 0.7187, 0.7299, 0.7252, 0.7197] / [0.7251, 0.7251, 0.7252, 0.7259, 0.7239, 0.7249, 0.7256], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:43,989] Trial 167 finished with value: 0.7235902335249659 and parameters: {'model__n_estimators': 50, 'model__learning_rate': 0.27, 'model__max_depth': 3, 'model__num_leaves': 248, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 5, 'model__lambda_l2': 75, 'model__bagging_fraction': 0.9000000000000001, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 100}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00348 train_set_score:0.7253\n",
      "folds val/train: [0.7239, 0.7245, 0.7235, 0.7189, 0.73, 0.7256, 0.7195] / [0.7253, 0.7251, 0.7253, 0.7261, 0.7241, 0.7251, 0.7258], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:46,280] Trial 168 finished with value: 0.7237056562323285 and parameters: {'model__n_estimators': 100, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 248, 'model__min_gain_to_split': 4.5, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 10, 'model__lambda_l2': 70, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 150}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00342 train_set_score:0.7251\n",
      "folds val/train: [0.7239, 0.7243, 0.7234, 0.7187, 0.7299, 0.7251, 0.7197] / [0.7251, 0.725, 0.7252, 0.7259, 0.7239, 0.725, 0.7256], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:48,538] Trial 169 finished with value: 0.7235808695427146 and parameters: {'model__n_estimators': 100, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 5.5, 'model__min_data_in_leaf': 600, 'model__lambda_l1': 5, 'model__lambda_l2': 70, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 100}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00360 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7247, 0.7236, 0.7187, 0.7304, 0.7258, 0.7198] / [0.7254, 0.7253, 0.7254, 0.7262, 0.7242, 0.7252, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:50,769] Trial 170 finished with value: 0.7238767437336573 and parameters: {'model__n_estimators': 150, 'model__learning_rate': 0.3, 'model__max_depth': 3, 'model__num_leaves': 256, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 400, 'model__lambda_l1': 10, 'model__lambda_l2': 80, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00360 train_set_score:0.7255\n",
      "folds val/train: [0.724, 0.7245, 0.7235, 0.7189, 0.7306, 0.7259, 0.7198] / [0.7256, 0.7255, 0.7256, 0.7263, 0.7242, 0.7252, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:53,025] Trial 171 finished with value: 0.723890544137203 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 240, 'model__min_gain_to_split': 3.0, 'model__min_data_in_leaf': 300, 'model__lambda_l1': 0, 'model__lambda_l2': 65, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00363 train_set_score:0.7255\n",
      "folds val/train: [0.724, 0.7246, 0.7235, 0.7188, 0.7305, 0.726, 0.7198] / [0.7256, 0.7254, 0.7256, 0.7261, 0.7239, 0.7254, 0.7262], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:55,370] Trial 172 finished with value: 0.723880023892842 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.27, 'model__max_depth': 3, 'model__num_leaves': 240, 'model__min_gain_to_split': 2.5, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 0, 'model__lambda_l2': 60, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00369 train_set_score:0.7251\n",
      "folds val/train: [0.7237, 0.7245, 0.7233, 0.7183, 0.7302, 0.7259, 0.7195] / [0.7251, 0.725, 0.7251, 0.7259, 0.724, 0.7249, 0.7257], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:57,714] Trial 173 finished with value: 0.7236021936146829 and parameters: {'model__n_estimators': 150, 'model__learning_rate': 0.28, 'model__max_depth': 3, 'model__num_leaves': 248, 'model__min_gain_to_split': 3.5, 'model__min_data_in_leaf': 300, 'model__lambda_l1': 100, 'model__lambda_l2': 65, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00347 train_set_score:0.7253\n",
      "folds val/train: [0.7238, 0.7246, 0.7235, 0.719, 0.7301, 0.7255, 0.7195] / [0.7254, 0.7253, 0.7253, 0.7261, 0.7242, 0.7249, 0.7258], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:05:59,948] Trial 174 finished with value: 0.7237125409534827 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.29000000000000004, 'model__max_depth': 3, 'model__num_leaves': 256, 'model__min_gain_to_split': 5.0, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 5, 'model__lambda_l2': 75, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 150}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00359 train_set_score:0.7254\n",
      "folds val/train: [0.7242, 0.7247, 0.7235, 0.7188, 0.7305, 0.7258, 0.7199] / [0.7254, 0.7254, 0.7255, 0.7262, 0.7239, 0.7252, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:02,186] Trial 175 finished with value: 0.7239122529300858 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.27, 'model__max_depth': 3, 'model__num_leaves': 248, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 400, 'model__lambda_l1': 0, 'model__lambda_l2': 60, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00342 train_set_score:0.7251\n",
      "folds val/train: [0.7239, 0.7243, 0.7234, 0.7187, 0.7299, 0.7252, 0.7197] / [0.7251, 0.7251, 0.7252, 0.7259, 0.7239, 0.7249, 0.7256], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:04,508] Trial 176 finished with value: 0.7235902335249659 and parameters: {'model__n_estimators': 50, 'model__learning_rate': 0.27, 'model__max_depth': 3, 'model__num_leaves': 248, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 400, 'model__lambda_l1': 5, 'model__lambda_l2': 75, 'model__bagging_fraction': 0.9000000000000001, 'model__feature_fraction': 0.4, 'model__max_bin': 100}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00360 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7246, 0.7236, 0.7188, 0.7305, 0.7258, 0.7198] / [0.7254, 0.7253, 0.7255, 0.7262, 0.7239, 0.7252, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:06,792] Trial 177 finished with value: 0.7239024991175371 and parameters: {'model__n_estimators': 150, 'model__learning_rate': 0.27, 'model__max_depth': 3, 'model__num_leaves': 256, 'model__min_gain_to_split': 7.5, 'model__min_data_in_leaf': 600, 'model__lambda_l1': 0, 'model__lambda_l2': 60, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.4, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00349 train_set_score:0.7252\n",
      "folds val/train: [0.7239, 0.7246, 0.7234, 0.7188, 0.73, 0.7255, 0.7195] / [0.7253, 0.7252, 0.7253, 0.726, 0.7239, 0.7251, 0.7258], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:09,100] Trial 178 finished with value: 0.7236669629050072 and parameters: {'model__n_estimators': 150, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 248, 'model__min_gain_to_split': 7.5, 'model__min_data_in_leaf': 800, 'model__lambda_l1': 5, 'model__lambda_l2': 60, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.2, 'model__max_bin': 150}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00361 train_set_score:0.7253\n",
      "folds val/train: [0.7241, 0.7247, 0.7236, 0.7188, 0.7305, 0.7259, 0.7199] / [0.7254, 0.7253, 0.7254, 0.7262, 0.7239, 0.7252, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:11,370] Trial 179 finished with value: 0.7239213696697606 and parameters: {'model__n_estimators': 150, 'model__learning_rate': 0.27, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 5, 'model__lambda_l2': 55, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00344 train_set_score:0.7251\n",
      "folds val/train: [0.7238, 0.7243, 0.7233, 0.7187, 0.73, 0.7251, 0.7198] / [0.7251, 0.725, 0.7252, 0.7259, 0.7239, 0.7249, 0.7256], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:13,641] Trial 180 finished with value: 0.723585853150184 and parameters: {'model__n_estimators': 150, 'model__learning_rate': 0.27, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 700, 'model__lambda_l1': 10, 'model__lambda_l2': 55, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 100}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00362 train_set_score:0.7253\n",
      "folds val/train: [0.7241, 0.7247, 0.7236, 0.7187, 0.7305, 0.726, 0.7199] / [0.7254, 0.7254, 0.7253, 0.7262, 0.7239, 0.7252, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:15,910] Trial 181 finished with value: 0.7239295889819102 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.27, 'model__max_depth': 3, 'model__num_leaves': 248, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 5, 'model__lambda_l2': 60, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00364 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7247, 0.7235, 0.7188, 0.7306, 0.7259, 0.7197] / [0.7254, 0.7254, 0.7255, 0.7263, 0.7239, 0.7252, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:18,201] Trial 182 finished with value: 0.7239038254256602 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 240, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 400, 'model__lambda_l1': 0, 'model__lambda_l2': 60, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00364 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7248, 0.7236, 0.7188, 0.7306, 0.7259, 0.7197] / [0.7255, 0.7253, 0.7255, 0.7263, 0.7239, 0.7252, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:20,454] Trial 183 finished with value: 0.7239132248728225 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 256, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 400, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00344 train_set_score:0.7253\n",
      "folds val/train: [0.7238, 0.7246, 0.7234, 0.7189, 0.7299, 0.7256, 0.7195] / [0.7253, 0.7251, 0.7254, 0.7262, 0.7239, 0.7251, 0.7258], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:22,728] Trial 184 finished with value: 0.7236834380054639 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 240, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 600, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.2, 'model__max_bin': 150}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00365 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7247, 0.7236, 0.7188, 0.7306, 0.7259, 0.7198] / [0.7254, 0.7254, 0.7255, 0.7262, 0.7239, 0.7252, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:25,039] Trial 185 finished with value: 0.7238991670419747 and parameters: {'model__n_estimators': 100, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 248, 'model__min_gain_to_split': 7.5, 'model__min_data_in_leaf': 400, 'model__lambda_l1': 0, 'model__lambda_l2': 60, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00364 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7248, 0.7235, 0.7188, 0.7306, 0.7259, 0.7197] / [0.7254, 0.7253, 0.7255, 0.7262, 0.7239, 0.7252, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:27,288] Trial 186 finished with value: 0.7239180127582718 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 248, 'model__min_gain_to_split': 7.0, 'model__min_data_in_leaf': 400, 'model__lambda_l1': 0, 'model__lambda_l2': 60, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00342 train_set_score:0.7252\n",
      "folds val/train: [0.724, 0.7243, 0.7233, 0.7187, 0.7298, 0.7251, 0.7196] / [0.7251, 0.7251, 0.7251, 0.726, 0.724, 0.725, 0.7258], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:29,611] Trial 187 finished with value: 0.7235533181747521 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 7.0, 'model__min_data_in_leaf': 400, 'model__lambda_l1': 0, 'model__lambda_l2': 60, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 100}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00363 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7247, 0.7235, 0.7188, 0.7306, 0.7259, 0.7198] / [0.7255, 0.7254, 0.7255, 0.7263, 0.7239, 0.7251, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:31,818] Trial 188 finished with value: 0.7239067165843579 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 0.9000000000000001, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00347 train_set_score:0.7252\n",
      "folds val/train: [0.7237, 0.7245, 0.7234, 0.7188, 0.7299, 0.7255, 0.7196] / [0.7252, 0.7252, 0.7252, 0.726, 0.7239, 0.725, 0.7258], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:34,167] Trial 189 finished with value: 0.7236412482347884 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 40, 'model__lambda_l2': 55, 'model__bagging_fraction': 0.9000000000000001, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 150}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00364 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7248, 0.7236, 0.7188, 0.7306, 0.7259, 0.7197] / [0.7255, 0.7253, 0.7255, 0.7263, 0.7239, 0.7252, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:36,409] Trial 190 finished with value: 0.7239173863560356 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00364 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7248, 0.7236, 0.7188, 0.7306, 0.7259, 0.7197] / [0.7255, 0.7253, 0.7255, 0.7263, 0.7239, 0.7252, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:38,682] Trial 191 finished with value: 0.7239173863560356 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00366 train_set_score:0.7253\n",
      "folds val/train: [0.7241, 0.7248, 0.7236, 0.7188, 0.7307, 0.7259, 0.7197] / [0.7254, 0.7253, 0.7255, 0.7261, 0.7239, 0.7253, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:40,987] Trial 192 finished with value: 0.7239300574339789 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00366 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7247, 0.7236, 0.7188, 0.7307, 0.7259, 0.7197] / [0.7254, 0.7253, 0.7255, 0.7262, 0.7239, 0.7253, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:43,224] Trial 193 finished with value: 0.7239237978953976 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 0, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00337 train_set_score:0.7251\n",
      "folds val/train: [0.724, 0.7243, 0.7235, 0.7188, 0.7298, 0.7251, 0.7198] / [0.7251, 0.7251, 0.7252, 0.7259, 0.724, 0.725, 0.7256], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:45,471] Trial 194 finished with value: 0.7236090301561955 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 216, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 0, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 100}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00345 train_set_score:0.7253\n",
      "folds val/train: [0.7239, 0.7246, 0.7234, 0.7189, 0.7299, 0.7256, 0.7195] / [0.7253, 0.7252, 0.7254, 0.7261, 0.7239, 0.7251, 0.726], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:47,740] Trial 195 finished with value: 0.7236959433537902 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 150}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00364 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7247, 0.7235, 0.7188, 0.7306, 0.7259, 0.7197] / [0.7255, 0.7254, 0.7254, 0.7263, 0.7239, 0.7252, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:50,116] Trial 196 finished with value: 0.7239030891115179 and parameters: {'model__n_estimators': 350, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 0, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00339 train_set_score:0.7251\n",
      "folds val/train: [0.7239, 0.7243, 0.7234, 0.7188, 0.7298, 0.7252, 0.7196] / [0.7251, 0.7252, 0.7251, 0.7259, 0.724, 0.725, 0.7256], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:52,419] Trial 197 finished with value: 0.7235952310341219 and parameters: {'model__n_estimators': 200, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 5, 'model__lambda_l2': 55, 'model__bagging_fraction': 0.9000000000000001, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 100}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00366 train_set_score:0.7253\n",
      "folds val/train: [0.724, 0.7248, 0.7236, 0.7188, 0.7307, 0.7259, 0.7197] / [0.7254, 0.7253, 0.7255, 0.7262, 0.7239, 0.7252, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:54,714] Trial 198 finished with value: 0.7239302332080874 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 216, 'model__min_gain_to_split': 7.0, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 0, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00346 train_set_score:0.7252\n",
      "folds val/train: [0.7235, 0.7245, 0.7233, 0.7187, 0.7298, 0.7255, 0.7196] / [0.7251, 0.7251, 0.7252, 0.7259, 0.7241, 0.7249, 0.7258], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:57,097] Trial 199 finished with value: 0.7235510883699249 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 216, 'model__min_gain_to_split': 7.0, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 60, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 150}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00368 train_set_score:0.7254\n",
      "folds val/train: [0.7242, 0.7248, 0.7232, 0.7186, 0.7306, 0.726, 0.7198] / [0.7254, 0.7253, 0.7256, 0.7263, 0.7242, 0.7253, 0.726], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:06:59,448] Trial 200 finished with value: 0.7238619194434998 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 4, 'model__num_leaves': 224, 'model__min_gain_to_split': 7.0, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 5, 'model__lambda_l2': 55, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00364 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7248, 0.7235, 0.7188, 0.7306, 0.7259, 0.7198] / [0.7255, 0.7253, 0.7255, 0.7262, 0.7239, 0.7252, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:01,738] Trial 201 finished with value: 0.7239116955953951 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 0, 'model__lambda_l2': 60, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00364 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7248, 0.7236, 0.7188, 0.7306, 0.7259, 0.7197] / [0.7255, 0.7253, 0.7255, 0.7263, 0.7239, 0.7252, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:04,011] Trial 202 finished with value: 0.7239173863560356 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.26, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00366 train_set_score:0.7253\n",
      "folds val/train: [0.7241, 0.7248, 0.7236, 0.7188, 0.7307, 0.7259, 0.7197] / [0.7254, 0.7253, 0.7255, 0.7261, 0.7239, 0.7253, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:06,238] Trial 203 finished with value: 0.7239300574339789 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00337 train_set_score:0.7251\n",
      "folds val/train: [0.724, 0.7243, 0.7235, 0.7188, 0.7298, 0.7251, 0.7198] / [0.7251, 0.725, 0.7251, 0.7259, 0.724, 0.725, 0.7256], mean fold time: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:08,456] Trial 204 finished with value: 0.7236076431174381 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 7.0, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 0, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 100}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00366 train_set_score:0.7253\n",
      "folds val/train: [0.7241, 0.7248, 0.7236, 0.7188, 0.7307, 0.7259, 0.7197] / [0.7254, 0.7253, 0.7255, 0.7261, 0.7239, 0.7253, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:10,707] Trial 205 finished with value: 0.7239300574339789 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 300, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00346 train_set_score:0.7253\n",
      "folds val/train: [0.7239, 0.7246, 0.7233, 0.7189, 0.7299, 0.7256, 0.7195] / [0.7254, 0.7253, 0.7254, 0.726, 0.7241, 0.7251, 0.726], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:13,021] Trial 206 finished with value: 0.7236509035403248 and parameters: {'model__n_estimators': 350, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 6.5, 'model__min_data_in_leaf': 300, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 150}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00373 train_set_score:0.7253\n",
      "folds val/train: [0.724, 0.7247, 0.7237, 0.7186, 0.7307, 0.726, 0.7197] / [0.7254, 0.7252, 0.7255, 0.7262, 0.7239, 0.7252, 0.7261], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:15,271] Trial 207 finished with value: 0.7239222240746058 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 7.0, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 5, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00346 train_set_score:0.7253\n",
      "folds val/train: [0.7238, 0.7246, 0.7234, 0.7189, 0.7299, 0.7256, 0.7195] / [0.7253, 0.7253, 0.7254, 0.7261, 0.7241, 0.7251, 0.7258], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:17,554] Trial 208 finished with value: 0.7236657631056821 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 208, 'model__min_gain_to_split': 7.0, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 5, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.2, 'model__max_bin': 150}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00338 train_set_score:0.7251\n",
      "folds val/train: [0.724, 0.7243, 0.7234, 0.7188, 0.7298, 0.7251, 0.7197] / [0.7251, 0.7251, 0.7251, 0.7259, 0.7242, 0.725, 0.7256], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:19,873] Trial 209 finished with value: 0.7235793587929437 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 3, 'model__num_leaves': 216, 'model__min_gain_to_split': 7.5, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 5, 'model__lambda_l2': 45, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 100}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00369 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7248, 0.7236, 0.7187, 0.7307, 0.7259, 0.7197] / [0.7254, 0.7253, 0.7254, 0.7262, 0.7239, 0.7252, 0.7261], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:22,134] Trial 210 finished with value: 0.7239228186660239 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 5, 'model__lambda_l2': 55, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00369 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7248, 0.7236, 0.7187, 0.7307, 0.7259, 0.7197] / [0.7254, 0.7253, 0.7254, 0.7262, 0.7239, 0.7252, 0.7261], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:24,417] Trial 211 finished with value: 0.7239228186660239 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 5, 'model__lambda_l2': 55, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00367 train_set_score:0.7253\n",
      "folds val/train: [0.724, 0.7247, 0.7235, 0.7187, 0.7307, 0.7258, 0.7198] / [0.7254, 0.7252, 0.7254, 0.726, 0.7239, 0.7252, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:26,636] Trial 212 finished with value: 0.7239053551869679 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 10, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00368 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7247, 0.7237, 0.7187, 0.7307, 0.7259, 0.7197] / [0.7255, 0.7253, 0.7255, 0.7262, 0.7241, 0.7252, 0.7259], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:28,995] Trial 213 finished with value: 0.7239126800408118 and parameters: {'model__n_estimators': 350, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 5, 'model__lambda_l2': 55, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00373 train_set_score:0.7253\n",
      "folds val/train: [0.724, 0.7247, 0.7237, 0.7186, 0.7307, 0.726, 0.7197] / [0.7254, 0.7252, 0.7255, 0.7262, 0.7239, 0.7252, 0.7261], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:31,339] Trial 214 finished with value: 0.7239222240746058 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 216, 'model__min_gain_to_split': 7.0, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 5, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00341 train_set_score:0.7251\n",
      "folds val/train: [0.7238, 0.7243, 0.7235, 0.7187, 0.7299, 0.7251, 0.7197] / [0.7251, 0.7251, 0.7251, 0.7259, 0.7242, 0.7249, 0.7256], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:33,600] Trial 215 finished with value: 0.7235832892743046 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 216, 'model__min_gain_to_split': 7.0, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 10, 'model__lambda_l2': 45, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 100}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00346 train_set_score:0.7253\n",
      "folds val/train: [0.7238, 0.7246, 0.7234, 0.7189, 0.7299, 0.7256, 0.7195] / [0.7253, 0.7253, 0.7254, 0.7261, 0.7241, 0.7251, 0.7258], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:35,844] Trial 216 finished with value: 0.7236657631056821 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 216, 'model__min_gain_to_split': 7.0, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 5, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 150}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00369 train_set_score:0.7253\n",
      "folds val/train: [0.7241, 0.7248, 0.7236, 0.7187, 0.7307, 0.7259, 0.7197] / [0.7254, 0.7253, 0.7254, 0.7262, 0.7239, 0.7252, 0.7261], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:38,178] Trial 217 finished with value: 0.723920919900562 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 5, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00369 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7248, 0.7235, 0.7187, 0.7307, 0.726, 0.7197] / [0.7255, 0.7254, 0.7255, 0.7261, 0.7239, 0.7252, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:40,529] Trial 218 finished with value: 0.7239211531826365 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 1.5, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 0, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00336 train_set_score:0.7252\n",
      "folds val/train: [0.7239, 0.7243, 0.7235, 0.7189, 0.7298, 0.7251, 0.7197] / [0.7251, 0.725, 0.7251, 0.7259, 0.7242, 0.725, 0.7258], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:42,918] Trial 219 finished with value: 0.7236086886082982 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 3, 'model__num_leaves': 208, 'model__min_gain_to_split': 6.0, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 5, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 100}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00369 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7248, 0.7235, 0.7187, 0.7307, 0.726, 0.7197] / [0.7255, 0.7254, 0.7255, 0.7261, 0.7239, 0.7252, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:45,200] Trial 220 finished with value: 0.7239211531826365 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 1.5, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 0, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00371 train_set_score:0.7253\n",
      "folds val/train: [0.724, 0.7247, 0.7236, 0.7187, 0.7307, 0.726, 0.7197] / [0.7254, 0.7251, 0.7255, 0.7262, 0.7239, 0.7252, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:47,449] Trial 221 finished with value: 0.7239217954142384 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 7.0, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 0, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00365 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7247, 0.7235, 0.7188, 0.7306, 0.726, 0.7197] / [0.7255, 0.7254, 0.7256, 0.7264, 0.7239, 0.7252, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:49,739] Trial 222 finished with value: 0.7238962002460028 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 1.0, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 0, 'model__lambda_l2': 45, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00368 train_set_score:0.7253\n",
      "folds val/train: [0.724, 0.7247, 0.7235, 0.7188, 0.7307, 0.7259, 0.7197] / [0.7255, 0.7254, 0.7254, 0.7261, 0.7239, 0.7253, 0.7259], mean fold time: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:51,949] Trial 223 finished with value: 0.7238953192920824 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 216, 'model__min_gain_to_split': 1.0, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 5, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00369 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7248, 0.7235, 0.7188, 0.7307, 0.726, 0.7197] / [0.7255, 0.7254, 0.7255, 0.7265, 0.7239, 0.7252, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:54,232] Trial 224 finished with value: 0.7239287146705767 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.23, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 1.0, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 0, 'model__lambda_l2': 45, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00343 train_set_score:0.7253\n",
      "folds val/train: [0.7238, 0.7246, 0.7232, 0.7189, 0.7299, 0.7256, 0.7196] / [0.7254, 0.7252, 0.7252, 0.7261, 0.7241, 0.7252, 0.7261], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:56,559] Trial 225 finished with value: 0.723671495911417 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.23, 'model__max_depth': 3, 'model__num_leaves': 216, 'model__min_gain_to_split': 0.0, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 5, 'model__lambda_l2': 40, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 150}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00365 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7247, 0.7235, 0.7188, 0.7306, 0.726, 0.7197] / [0.7255, 0.7255, 0.7256, 0.7263, 0.7239, 0.7253, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:07:58,878] Trial 226 finished with value: 0.7238914032254764 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 1.5, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 0, 'model__lambda_l2': 45, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.2, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00339 train_set_score:0.7251\n",
      "folds val/train: [0.7238, 0.7242, 0.7234, 0.7188, 0.7298, 0.7252, 0.7197] / [0.7251, 0.7252, 0.7251, 0.726, 0.7236, 0.725, 0.7258], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:01,264] Trial 227 finished with value: 0.7235745572230856 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.23, 'model__max_depth': 3, 'model__num_leaves': 216, 'model__min_gain_to_split': 1.5, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 10, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 100}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00369 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7247, 0.7235, 0.7188, 0.7307, 0.726, 0.7197] / [0.7255, 0.7254, 0.7254, 0.7261, 0.7239, 0.7253, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:03,538] Trial 228 finished with value: 0.7239085813425559 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 0.5, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 5, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00342 train_set_score:0.7254\n",
      "folds val/train: [0.7239, 0.7245, 0.7233, 0.719, 0.7299, 0.7257, 0.7196] / [0.7256, 0.7253, 0.7254, 0.7264, 0.7242, 0.7252, 0.726], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:05,940] Trial 229 finished with value: 0.7236853975627708 and parameters: {'model__n_estimators': 250, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 3, 'model__num_leaves': 208, 'model__min_gain_to_split': 2.0, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 0, 'model__lambda_l2': 45, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 150}. Best is trial 161 with value: 0.7239376786470416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7240, std_test_score:0.00366 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7247, 0.7235, 0.7189, 0.7307, 0.7261, 0.7198] / [0.7255, 0.7254, 0.7255, 0.7261, 0.7239, 0.7254, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:08,226] Trial 230 finished with value: 0.7239502969915346 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 1.5, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 0, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 230 with value: 0.7239502969915346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7240, std_test_score:0.00366 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7247, 0.7235, 0.7189, 0.7307, 0.7261, 0.7198] / [0.7255, 0.7254, 0.7255, 0.7261, 0.7239, 0.7254, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:10,477] Trial 231 finished with value: 0.7239502969915346 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 1.5, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 0, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 230 with value: 0.7239502969915346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00369 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7248, 0.7235, 0.7187, 0.7307, 0.726, 0.7197] / [0.7255, 0.7254, 0.7255, 0.7261, 0.7239, 0.7252, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:12,724] Trial 232 finished with value: 0.7239211531826365 and parameters: {'model__n_estimators': 350, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 1.5, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 0, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 230 with value: 0.7239502969915346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00369 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7248, 0.7235, 0.7187, 0.7307, 0.726, 0.7197] / [0.7255, 0.7254, 0.7255, 0.7261, 0.7239, 0.7252, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:15,017] Trial 233 finished with value: 0.7239211531826365 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 3, 'model__num_leaves': 216, 'model__min_gain_to_split': 1.5, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 0, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 230 with value: 0.7239502969915346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00370 train_set_score:0.7255\n",
      "folds val/train: [0.724, 0.7248, 0.7235, 0.7187, 0.7307, 0.726, 0.7197] / [0.7256, 0.7254, 0.7255, 0.7264, 0.7239, 0.7253, 0.7261], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:17,383] Trial 234 finished with value: 0.723929287414604 and parameters: {'model__n_estimators': 350, 'model__learning_rate': 0.23, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 2.0, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 0, 'model__lambda_l2': 45, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 230 with value: 0.7239502969915346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00339 train_set_score:0.7252\n",
      "folds val/train: [0.724, 0.7243, 0.7233, 0.7186, 0.7299, 0.7251, 0.72] / [0.7252, 0.7252, 0.7252, 0.726, 0.7242, 0.725, 0.7256], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:19,675] Trial 235 finished with value: 0.7236138547641585 and parameters: {'model__n_estimators': 350, 'model__learning_rate': 0.23, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 1.0, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 0, 'model__lambda_l2': 45, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 100}. Best is trial 230 with value: 0.7239502969915346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00357 train_set_score:0.7273\n",
      "folds val/train: [0.724, 0.7242, 0.7233, 0.7188, 0.7305, 0.7251, 0.7197] / [0.7276, 0.7272, 0.7269, 0.7281, 0.7261, 0.7272, 0.7281], mean fold time: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:22,103] Trial 236 finished with value: 0.723650008478254 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.23, 'model__max_depth': 3, 'model__num_leaves': 216, 'model__min_gain_to_split': 2.0, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 0, 'model__lambda_l2': 45, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.9000000000000001, 'model__max_bin': 125}. Best is trial 230 with value: 0.7239502969915346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00342 train_set_score:0.7254\n",
      "folds val/train: [0.7238, 0.7246, 0.7233, 0.719, 0.7299, 0.7256, 0.7196] / [0.7254, 0.7254, 0.7252, 0.7266, 0.7241, 0.7252, 0.7258], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:24,520] Trial 237 finished with value: 0.7236813296742852 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 1.0, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 5, 'model__lambda_l2': 40, 'model__bagging_fraction': 0.2, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 150}. Best is trial 230 with value: 0.7239502969915346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00364 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7248, 0.7235, 0.7188, 0.7306, 0.726, 0.7197] / [0.7255, 0.7254, 0.7256, 0.7266, 0.7239, 0.7252, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:26,847] Trial 238 finished with value: 0.7239060237124981 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.24000000000000002, 'model__max_depth': 3, 'model__num_leaves': 208, 'model__min_gain_to_split': 0.5, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 0, 'model__lambda_l2': 45, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 230 with value: 0.7239502969915346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00339 train_set_score:0.7252\n",
      "folds val/train: [0.7239, 0.7243, 0.7234, 0.7188, 0.7298, 0.7251, 0.7196] / [0.7253, 0.7252, 0.7252, 0.7259, 0.724, 0.725, 0.7256], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:29,112] Trial 239 finished with value: 0.7235698115575043 and parameters: {'model__n_estimators': 350, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 2.0, 'model__min_data_in_leaf': 200, 'model__lambda_l1': 5, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 100}. Best is trial 230 with value: 0.7239502969915346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00366 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7247, 0.7236, 0.7189, 0.7307, 0.726, 0.7198] / [0.7255, 0.7254, 0.7255, 0.7261, 0.7242, 0.7253, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:31,367] Trial 240 finished with value: 0.7239410978429985 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 1.5, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 230 with value: 0.7239502969915346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00366 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7247, 0.7236, 0.7189, 0.7307, 0.726, 0.7198] / [0.7255, 0.7254, 0.7255, 0.7261, 0.7242, 0.7253, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:33,677] Trial 241 finished with value: 0.7239410978429985 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 1.5, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 0.30000000000000004, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 230 with value: 0.7239502969915346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00366 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7247, 0.7235, 0.7189, 0.7307, 0.7261, 0.7198] / [0.7255, 0.7254, 0.7255, 0.7261, 0.7242, 0.7254, 0.7259], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:36,015] Trial 242 finished with value: 0.7239450405610407 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 2.5, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 0.30000000000000004, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 230 with value: 0.7239502969915346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00366 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7247, 0.7236, 0.7189, 0.7307, 0.726, 0.7198] / [0.7255, 0.7254, 0.7255, 0.7261, 0.7242, 0.7253, 0.7259], mean fold time: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:38,397] Trial 243 finished with value: 0.7239381035171804 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 2.0, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 0.30000000000000004, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 230 with value: 0.7239502969915346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00366 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7247, 0.7235, 0.7189, 0.7307, 0.7261, 0.7198] / [0.7255, 0.7254, 0.7255, 0.7261, 0.7242, 0.7254, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:40,672] Trial 244 finished with value: 0.7239450405610407 and parameters: {'model__n_estimators': 350, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 2.5, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 0.30000000000000004, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 230 with value: 0.7239502969915346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00345 train_set_score:0.7253\n",
      "folds val/train: [0.7239, 0.7246, 0.7233, 0.7189, 0.7299, 0.7256, 0.7195] / [0.7254, 0.7252, 0.7252, 0.7263, 0.7239, 0.7252, 0.7261], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:42,977] Trial 245 finished with value: 0.723674688356077 and parameters: {'model__n_estimators': 350, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 2.5, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 0.30000000000000004, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 150}. Best is trial 230 with value: 0.7239502969915346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00366 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7247, 0.7235, 0.7189, 0.7307, 0.7261, 0.7198] / [0.7255, 0.7254, 0.7255, 0.7261, 0.7242, 0.7254, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:45,222] Trial 246 finished with value: 0.7239450405610407 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 2.5, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 0.30000000000000004, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}. Best is trial 230 with value: 0.7239502969915346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7236, std_test_score:0.00340 train_set_score:0.7252\n",
      "folds val/train: [0.7238, 0.7244, 0.7232, 0.7188, 0.7299, 0.7251, 0.7197] / [0.7252, 0.7252, 0.7253, 0.7259, 0.7242, 0.7251, 0.7256], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:47,503] Trial 247 finished with value: 0.7235560024824644 and parameters: {'model__n_estimators': 300, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 2.5, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 0.30000000000000004, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 100}. Best is trial 230 with value: 0.7239502969915346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7239, std_test_score:0.00366 train_set_score:0.7254\n",
      "folds val/train: [0.7241, 0.7247, 0.7236, 0.7189, 0.7307, 0.726, 0.7198] / [0.7255, 0.7254, 0.7255, 0.7261, 0.7242, 0.7253, 0.7259], mean fold time: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:49,734] Trial 248 finished with value: 0.7239381035171804 and parameters: {'model__n_estimators': 350, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 232, 'model__min_gain_to_split': 2.0, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 0.30000000000000004, 'model__feature_fraction': 0.2, 'model__max_bin': 125}. Best is trial 230 with value: 0.7239502969915346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: Tuning: n_train=263580, eval_set=43931\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Fold: Tuning: n_train=263581, eval_set=43930\n",
      "Tune: val_score:0.7237, std_test_score:0.00343 train_set_score:0.7254\n",
      "folds val/train: [0.724, 0.7246, 0.7233, 0.719, 0.7299, 0.7256, 0.7195] / [0.7254, 0.7254, 0.7252, 0.7264, 0.7239, 0.7253, 0.7261], mean fold time: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-29 22:08:52,046] Trial 249 finished with value: 0.7236990920618321 and parameters: {'model__n_estimators': 400, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 240, 'model__min_gain_to_split': 2.0, 'model__min_data_in_leaf': 0, 'model__lambda_l1': 0, 'model__lambda_l2': 55, 'model__bagging_fraction': 0.30000000000000004, 'model__feature_fraction': 0.2, 'model__max_bin': 150}. Best is trial 230 with value: 0.7239502969915346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -- -- --\n",
      " TUNING RESULT: \n",
      " Baseline_Only_CreditRatings: auc = 0.7239502969915346 params: {'model__n_estimators': 300, 'model__learning_rate': 0.25, 'model__max_depth': 3, 'model__num_leaves': 224, 'model__min_gain_to_split': 1.5, 'model__min_data_in_leaf': 100, 'model__lambda_l1': 0, 'model__lambda_l2': 50, 'model__bagging_fraction': 1.0, 'model__feature_fraction': 0.30000000000000004, 'model__max_bin': 125}\n",
      " -- --\n",
      "\n",
      "Baseline_Only_CreditRatings Fit, total time:592.8\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "for t, v in tuning_results.items():\n",
    "    display(t)\n",
    "    display(v.hyper_param_all_cv_results)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T18:09:21.113899Z",
     "start_time": "2024-04-28T18:09:21.095753Z"
    }
   },
   "id": "23fac5165a6b77dd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LGBM_AUC'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "     Trial Number  Mean Test Score (AUC)  mean_test_score  mean_train_score  \\\n",
       "231           231               0.776092         0.776092          0.843902   \n",
       "193           193               0.775960         0.775960          0.849419   \n",
       "161           161               0.775731         0.775731          0.833488   \n",
       "227           227               0.775717         0.775717          0.842292   \n",
       "190           190               0.775712         0.775712          0.848627   \n",
       "..            ...                    ...              ...               ...   \n",
       "44             44               0.759950         0.759950          0.775641   \n",
       "128           128               0.756286         0.756286          0.781508   \n",
       "174           174               0.748395         0.748395          0.768160   \n",
       "146           146               0.747943         0.747943          0.765273   \n",
       "65             65               0.728706         0.728706          0.737987   \n",
       "\n",
       "     std_test_score  macro_f1  micro_f1  f1_target1  precision_target1  \\\n",
       "231        0.003024  0.566457  0.740422    0.291828           0.187127   \n",
       "193        0.003408  0.567945  0.742949    0.292970           0.188295   \n",
       "161        0.003669  0.563487  0.735092    0.289794           0.184919   \n",
       "227        0.003251  0.565909  0.739749    0.291205           0.186638   \n",
       "190        0.003517  0.567445  0.742686    0.292125           0.187762   \n",
       "..              ...       ...       ...         ...                ...   \n",
       "44         0.012737  0.541356  0.701113    0.270669           0.168534   \n",
       "128        0.003210  0.542204  0.704303    0.269791           0.168484   \n",
       "174        0.003632  0.536500  0.697191    0.263589           0.163990   \n",
       "146        0.003534  0.535045  0.694596    0.262677           0.163133   \n",
       "65         0.004293  0.518625  0.672282    0.246657           0.151430   \n",
       "\n",
       "     recall_target1  log_loss    pr_auc  mean_fold_time  \\\n",
       "231        0.662518  0.527647  0.263602        6.471375   \n",
       "193        0.659698  0.524256  0.263453        6.741207   \n",
       "161        0.669486  0.534421  0.263478        5.783973   \n",
       "227        0.662236  0.528503  0.263391        5.505174   \n",
       "190        0.657684  0.524701  0.263422        6.676134   \n",
       "..              ...       ...       ...             ...   \n",
       "44         0.687009  0.595431  0.226876        5.571353   \n",
       "128        0.676657  0.599644  0.235728        1.633354   \n",
       "174        0.671299  0.661424  0.216286        1.595065   \n",
       "146        0.673877  0.664139  0.215530        1.512120   \n",
       "65         0.664572  0.678073  0.204146        1.263590   \n",
       "\n",
       "                                            Parameters  \n",
       "231  {'model__objective': 'binary', 'model__class_w...  \n",
       "193  {'model__objective': 'binary', 'model__class_w...  \n",
       "161  {'model__objective': 'binary', 'model__class_w...  \n",
       "227  {'model__objective': 'binary', 'model__class_w...  \n",
       "190  {'model__objective': 'binary', 'model__class_w...  \n",
       "..                                                 ...  \n",
       "44   {'model__objective': 'binary', 'model__class_w...  \n",
       "128  {'model__objective': 'binary', 'model__class_w...  \n",
       "174  {'model__objective': 'binary', 'model__class_w...  \n",
       "146  {'model__objective': 'binary', 'model__class_w...  \n",
       "65   {'model__objective': 'binary', 'model__class_w...  \n",
       "\n",
       "[250 rows x 14 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial Number</th>\n",
       "      <th>Mean Test Score (AUC)</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>micro_f1</th>\n",
       "      <th>f1_target1</th>\n",
       "      <th>precision_target1</th>\n",
       "      <th>recall_target1</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>mean_fold_time</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>231</td>\n",
       "      <td>0.776092</td>\n",
       "      <td>0.776092</td>\n",
       "      <td>0.843902</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.566457</td>\n",
       "      <td>0.740422</td>\n",
       "      <td>0.291828</td>\n",
       "      <td>0.187127</td>\n",
       "      <td>0.662518</td>\n",
       "      <td>0.527647</td>\n",
       "      <td>0.263602</td>\n",
       "      <td>6.471375</td>\n",
       "      <td>{'model__objective': 'binary', 'model__class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>193</td>\n",
       "      <td>0.775960</td>\n",
       "      <td>0.775960</td>\n",
       "      <td>0.849419</td>\n",
       "      <td>0.003408</td>\n",
       "      <td>0.567945</td>\n",
       "      <td>0.742949</td>\n",
       "      <td>0.292970</td>\n",
       "      <td>0.188295</td>\n",
       "      <td>0.659698</td>\n",
       "      <td>0.524256</td>\n",
       "      <td>0.263453</td>\n",
       "      <td>6.741207</td>\n",
       "      <td>{'model__objective': 'binary', 'model__class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>161</td>\n",
       "      <td>0.775731</td>\n",
       "      <td>0.775731</td>\n",
       "      <td>0.833488</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>0.563487</td>\n",
       "      <td>0.735092</td>\n",
       "      <td>0.289794</td>\n",
       "      <td>0.184919</td>\n",
       "      <td>0.669486</td>\n",
       "      <td>0.534421</td>\n",
       "      <td>0.263478</td>\n",
       "      <td>5.783973</td>\n",
       "      <td>{'model__objective': 'binary', 'model__class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>227</td>\n",
       "      <td>0.775717</td>\n",
       "      <td>0.775717</td>\n",
       "      <td>0.842292</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>0.565909</td>\n",
       "      <td>0.739749</td>\n",
       "      <td>0.291205</td>\n",
       "      <td>0.186638</td>\n",
       "      <td>0.662236</td>\n",
       "      <td>0.528503</td>\n",
       "      <td>0.263391</td>\n",
       "      <td>5.505174</td>\n",
       "      <td>{'model__objective': 'binary', 'model__class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>190</td>\n",
       "      <td>0.775712</td>\n",
       "      <td>0.775712</td>\n",
       "      <td>0.848627</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>0.567445</td>\n",
       "      <td>0.742686</td>\n",
       "      <td>0.292125</td>\n",
       "      <td>0.187762</td>\n",
       "      <td>0.657684</td>\n",
       "      <td>0.524701</td>\n",
       "      <td>0.263422</td>\n",
       "      <td>6.676134</td>\n",
       "      <td>{'model__objective': 'binary', 'model__class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0.759950</td>\n",
       "      <td>0.759950</td>\n",
       "      <td>0.775641</td>\n",
       "      <td>0.012737</td>\n",
       "      <td>0.541356</td>\n",
       "      <td>0.701113</td>\n",
       "      <td>0.270669</td>\n",
       "      <td>0.168534</td>\n",
       "      <td>0.687009</td>\n",
       "      <td>0.595431</td>\n",
       "      <td>0.226876</td>\n",
       "      <td>5.571353</td>\n",
       "      <td>{'model__objective': 'binary', 'model__class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128</td>\n",
       "      <td>0.756286</td>\n",
       "      <td>0.756286</td>\n",
       "      <td>0.781508</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>0.542204</td>\n",
       "      <td>0.704303</td>\n",
       "      <td>0.269791</td>\n",
       "      <td>0.168484</td>\n",
       "      <td>0.676657</td>\n",
       "      <td>0.599644</td>\n",
       "      <td>0.235728</td>\n",
       "      <td>1.633354</td>\n",
       "      <td>{'model__objective': 'binary', 'model__class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>174</td>\n",
       "      <td>0.748395</td>\n",
       "      <td>0.748395</td>\n",
       "      <td>0.768160</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.536500</td>\n",
       "      <td>0.697191</td>\n",
       "      <td>0.263589</td>\n",
       "      <td>0.163990</td>\n",
       "      <td>0.671299</td>\n",
       "      <td>0.661424</td>\n",
       "      <td>0.216286</td>\n",
       "      <td>1.595065</td>\n",
       "      <td>{'model__objective': 'binary', 'model__class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>146</td>\n",
       "      <td>0.747943</td>\n",
       "      <td>0.747943</td>\n",
       "      <td>0.765273</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>0.535045</td>\n",
       "      <td>0.694596</td>\n",
       "      <td>0.262677</td>\n",
       "      <td>0.163133</td>\n",
       "      <td>0.673877</td>\n",
       "      <td>0.664139</td>\n",
       "      <td>0.215530</td>\n",
       "      <td>1.512120</td>\n",
       "      <td>{'model__objective': 'binary', 'model__class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>0.728706</td>\n",
       "      <td>0.728706</td>\n",
       "      <td>0.737987</td>\n",
       "      <td>0.004293</td>\n",
       "      <td>0.518625</td>\n",
       "      <td>0.672282</td>\n",
       "      <td>0.246657</td>\n",
       "      <td>0.151430</td>\n",
       "      <td>0.664572</td>\n",
       "      <td>0.678073</td>\n",
       "      <td>0.204146</td>\n",
       "      <td>1.263590</td>\n",
       "      <td>{'model__objective': 'binary', 'model__class_w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows  14 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'LGBM_Dart_AUC'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "     Trial Number  Mean Test Score (AUC)  mean_test_score  mean_train_score  \\\n",
       "242           242               0.777050         0.777050          0.823991   \n",
       "219           219               0.776988         0.776988          0.827738   \n",
       "181           181               0.776971         0.776971          0.820890   \n",
       "148           148               0.776938         0.776938          0.825691   \n",
       "223           223               0.776937         0.776937          0.827678   \n",
       "..            ...                    ...              ...               ...   \n",
       "2               2               0.762608         0.762608          0.782228   \n",
       "5               5               0.760132         0.760132          0.783908   \n",
       "164           164               0.758951         0.758951          0.772656   \n",
       "56             56               0.756898         0.756898          0.773740   \n",
       "18             18               0.755542         0.755542          0.772639   \n",
       "\n",
       "     std_test_score  macro_f1  micro_f1  f1_target1  precision_target1  \\\n",
       "242        0.003522  0.561941  0.731262    0.289595           0.184081   \n",
       "219        0.003543  0.562456  0.732562    0.289638           0.184349   \n",
       "181        0.003434  0.560811  0.729519    0.288608           0.183202   \n",
       "148        0.003266  0.562256  0.732013    0.289657           0.184257   \n",
       "223        0.003326  0.562959  0.732803    0.290510           0.184888   \n",
       "..              ...       ...       ...         ...                ...   \n",
       "2          0.003897  0.545220  0.707149    0.273850           0.171193   \n",
       "5          0.003648  0.543841  0.705676    0.272139           0.170011   \n",
       "164        0.003895  0.540465  0.700160    0.269567           0.167779   \n",
       "56         0.003494  0.539982  0.700499    0.268246           0.167077   \n",
       "18         0.003598  0.538572  0.698099    0.267261           0.166194   \n",
       "\n",
       "     recall_target1  log_loss    pr_auc  mean_fold_time  \\\n",
       "242        0.678510  0.539715  0.265901       18.134199   \n",
       "219        0.675368  0.537131  0.265637       22.858985   \n",
       "181        0.679637  0.541838  0.265183       18.932894   \n",
       "148        0.676818  0.538614  0.265921       18.012119   \n",
       "223        0.677623  0.537636  0.266211       20.997200   \n",
       "..              ...       ...       ...             ...   \n",
       "2          0.684028  0.578606  0.243208        4.888875   \n",
       "5          0.681571  0.588143  0.241381        8.437506   \n",
       "164        0.685358  0.580540  0.241095        1.428431   \n",
       "56         0.680000  0.585412  0.238343       21.932889   \n",
       "18         0.682014  0.603566  0.235969        1.496876   \n",
       "\n",
       "                                            Parameters  \n",
       "242  {'model__boosting_type': 'dart', 'model__objec...  \n",
       "219  {'model__boosting_type': 'dart', 'model__objec...  \n",
       "181  {'model__boosting_type': 'dart', 'model__objec...  \n",
       "148  {'model__boosting_type': 'dart', 'model__objec...  \n",
       "223  {'model__boosting_type': 'dart', 'model__objec...  \n",
       "..                                                 ...  \n",
       "2    {'model__boosting_type': 'dart', 'model__objec...  \n",
       "5    {'model__boosting_type': 'dart', 'model__objec...  \n",
       "164  {'model__boosting_type': 'dart', 'model__objec...  \n",
       "56   {'model__boosting_type': 'dart', 'model__objec...  \n",
       "18   {'model__boosting_type': 'dart', 'model__objec...  \n",
       "\n",
       "[250 rows x 14 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial Number</th>\n",
       "      <th>Mean Test Score (AUC)</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>micro_f1</th>\n",
       "      <th>f1_target1</th>\n",
       "      <th>precision_target1</th>\n",
       "      <th>recall_target1</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>mean_fold_time</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>242</td>\n",
       "      <td>0.777050</td>\n",
       "      <td>0.777050</td>\n",
       "      <td>0.823991</td>\n",
       "      <td>0.003522</td>\n",
       "      <td>0.561941</td>\n",
       "      <td>0.731262</td>\n",
       "      <td>0.289595</td>\n",
       "      <td>0.184081</td>\n",
       "      <td>0.678510</td>\n",
       "      <td>0.539715</td>\n",
       "      <td>0.265901</td>\n",
       "      <td>18.134199</td>\n",
       "      <td>{'model__boosting_type': 'dart', 'model__objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>219</td>\n",
       "      <td>0.776988</td>\n",
       "      <td>0.776988</td>\n",
       "      <td>0.827738</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>0.562456</td>\n",
       "      <td>0.732562</td>\n",
       "      <td>0.289638</td>\n",
       "      <td>0.184349</td>\n",
       "      <td>0.675368</td>\n",
       "      <td>0.537131</td>\n",
       "      <td>0.265637</td>\n",
       "      <td>22.858985</td>\n",
       "      <td>{'model__boosting_type': 'dart', 'model__objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>0.776971</td>\n",
       "      <td>0.776971</td>\n",
       "      <td>0.820890</td>\n",
       "      <td>0.003434</td>\n",
       "      <td>0.560811</td>\n",
       "      <td>0.729519</td>\n",
       "      <td>0.288608</td>\n",
       "      <td>0.183202</td>\n",
       "      <td>0.679637</td>\n",
       "      <td>0.541838</td>\n",
       "      <td>0.265183</td>\n",
       "      <td>18.932894</td>\n",
       "      <td>{'model__boosting_type': 'dart', 'model__objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>148</td>\n",
       "      <td>0.776938</td>\n",
       "      <td>0.776938</td>\n",
       "      <td>0.825691</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>0.562256</td>\n",
       "      <td>0.732013</td>\n",
       "      <td>0.289657</td>\n",
       "      <td>0.184257</td>\n",
       "      <td>0.676818</td>\n",
       "      <td>0.538614</td>\n",
       "      <td>0.265921</td>\n",
       "      <td>18.012119</td>\n",
       "      <td>{'model__boosting_type': 'dart', 'model__objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>223</td>\n",
       "      <td>0.776937</td>\n",
       "      <td>0.776937</td>\n",
       "      <td>0.827678</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>0.562959</td>\n",
       "      <td>0.732803</td>\n",
       "      <td>0.290510</td>\n",
       "      <td>0.184888</td>\n",
       "      <td>0.677623</td>\n",
       "      <td>0.537636</td>\n",
       "      <td>0.266211</td>\n",
       "      <td>20.997200</td>\n",
       "      <td>{'model__boosting_type': 'dart', 'model__objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.762608</td>\n",
       "      <td>0.762608</td>\n",
       "      <td>0.782228</td>\n",
       "      <td>0.003897</td>\n",
       "      <td>0.545220</td>\n",
       "      <td>0.707149</td>\n",
       "      <td>0.273850</td>\n",
       "      <td>0.171193</td>\n",
       "      <td>0.684028</td>\n",
       "      <td>0.578606</td>\n",
       "      <td>0.243208</td>\n",
       "      <td>4.888875</td>\n",
       "      <td>{'model__boosting_type': 'dart', 'model__objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.760132</td>\n",
       "      <td>0.760132</td>\n",
       "      <td>0.783908</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.543841</td>\n",
       "      <td>0.705676</td>\n",
       "      <td>0.272139</td>\n",
       "      <td>0.170011</td>\n",
       "      <td>0.681571</td>\n",
       "      <td>0.588143</td>\n",
       "      <td>0.241381</td>\n",
       "      <td>8.437506</td>\n",
       "      <td>{'model__boosting_type': 'dart', 'model__objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>164</td>\n",
       "      <td>0.758951</td>\n",
       "      <td>0.758951</td>\n",
       "      <td>0.772656</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.540465</td>\n",
       "      <td>0.700160</td>\n",
       "      <td>0.269567</td>\n",
       "      <td>0.167779</td>\n",
       "      <td>0.685358</td>\n",
       "      <td>0.580540</td>\n",
       "      <td>0.241095</td>\n",
       "      <td>1.428431</td>\n",
       "      <td>{'model__boosting_type': 'dart', 'model__objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>0.756898</td>\n",
       "      <td>0.756898</td>\n",
       "      <td>0.773740</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.539982</td>\n",
       "      <td>0.700499</td>\n",
       "      <td>0.268246</td>\n",
       "      <td>0.167077</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.585412</td>\n",
       "      <td>0.238343</td>\n",
       "      <td>21.932889</td>\n",
       "      <td>{'model__boosting_type': 'dart', 'model__objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.755542</td>\n",
       "      <td>0.755542</td>\n",
       "      <td>0.772639</td>\n",
       "      <td>0.003598</td>\n",
       "      <td>0.538572</td>\n",
       "      <td>0.698099</td>\n",
       "      <td>0.267261</td>\n",
       "      <td>0.166194</td>\n",
       "      <td>0.682014</td>\n",
       "      <td>0.603566</td>\n",
       "      <td>0.235969</td>\n",
       "      <td>1.496876</td>\n",
       "      <td>{'model__boosting_type': 'dart', 'model__objec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows  14 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": "tuning_results.keys()",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T17:43:58.384059Z",
     "start_time": "2024-04-20T17:43:58.380984Z"
    }
   },
   "id": "27ceb3ef64dae1f2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['LGBM_Dart_AUC', 'LGBM_AUC'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "# Results:\n",
    "\n",
    "# Only main dataset:\n",
    "# - top res      : 0.753\n",
    "# - full + gbdt  : 0.765\n",
    "# - full + dart  : 0.766\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T17:43:58.386175Z",
     "start_time": "2024-04-20T17:43:58.384059Z"
    }
   },
   "id": "455694eed5002c55",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "from Draft.feature_builder_v2 import DatasetType\n",
    "\n",
    "importlib.reload(feature_builder_v2)\n",
    "features_matrix_full = feature_builder_v2.load_datasets_and_prepare_features(drop_meta_data=True,\n",
    "                                                                             ds_type=DatasetType.FULL)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T17:44:17.764720Z",
     "start_time": "2024-04-20T17:43:58.386175Z"
    }
   },
   "id": "fed6d85344fbd3e1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\featuretools\\entityset\\entityset.py:1914: UserWarning: index SK_BUREAU_ID not found in dataframe, creating new integer column\n",
      "  warnings.warn(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\featuretools\\computational_backends\\feature_set_calculator.py:828: FutureWarning: The provided callable <function mean at 0x0000020748304D60> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  ).agg(to_agg)\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\featuretools\\computational_backends\\feature_set_calculator.py:828: FutureWarning: The provided callable <function min at 0x00000207483044A0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
      "  ).agg(to_agg)\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\featuretools\\computational_backends\\feature_set_calculator.py:828: FutureWarning: The provided callable <function max at 0x0000020748304360> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  ).agg(to_agg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending previous history\n",
      "Full DS size: 307511\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "features_matrix_full"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T17:44:17.804201Z",
     "start_time": "2024-04-20T17:44:17.764720Z"
    }
   },
   "id": "554658483974d14c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        TARGET NameContractType CodeGender  FlagOwnCar  FlagOwnRealty  \\\n",
       "0            1       Cash loans          M       False           True   \n",
       "1            0       Cash loans          F       False          False   \n",
       "2            0  Revolving loans          M        True           True   \n",
       "3            0       Cash loans          F       False           True   \n",
       "4            0       Cash loans          M       False           True   \n",
       "...        ...              ...        ...         ...            ...   \n",
       "307506       0       Cash loans          M       False          False   \n",
       "307507       0       Cash loans          F       False           True   \n",
       "307508       0       Cash loans          F       False           True   \n",
       "307509       1       Cash loans          F       False           True   \n",
       "307510       0       Cash loans          F       False          False   \n",
       "\n",
       "        CntChildren  AmtIncomeTotal  AmtCredit  AmtAnnuity  AmtGoodsPrice  \\\n",
       "0                 0        202500.0   406597.5     24700.5       351000.0   \n",
       "1                 0        270000.0  1293502.5     35698.5      1129500.0   \n",
       "2                 0         67500.0   135000.0      6750.0       135000.0   \n",
       "3                 0        135000.0   312682.5     29686.5       297000.0   \n",
       "4                 0        121500.0   513000.0     21865.5       513000.0   \n",
       "...             ...             ...        ...         ...            ...   \n",
       "307506            0        157500.0   254700.0     27558.0       225000.0   \n",
       "307507            0         72000.0   269550.0     12001.5       225000.0   \n",
       "307508            0        153000.0   677664.0     29979.0       585000.0   \n",
       "307509            0        171000.0   370107.0     20205.0       319500.0   \n",
       "307510            0        157500.0   675000.0     49117.5       675000.0   \n",
       "\n",
       "        ... PrevCodeRejectReasonHcCount PrevCodeRejectReasonLimitCount  \\\n",
       "0       ...                         0.0                            0.0   \n",
       "1       ...                         0.0                            0.0   \n",
       "2       ...                         0.0                            0.0   \n",
       "3       ...                         0.0                            1.0   \n",
       "4       ...                         0.0                            0.0   \n",
       "...     ...                         ...                            ...   \n",
       "307506  ...                         0.0                            0.0   \n",
       "307507  ...                         0.0                            0.0   \n",
       "307508  ...                         0.0                            0.0   \n",
       "307509  ...                         0.0                            0.0   \n",
       "307510  ...                         2.0                            0.0   \n",
       "\n",
       "       PrevCodeRejectReasonScoCount PrevCodeRejectReasonScofrCount  \\\n",
       "0                               0.0                            0.0   \n",
       "1                               0.0                            0.0   \n",
       "2                               0.0                            0.0   \n",
       "3                               0.0                            0.0   \n",
       "4                               0.0                            0.0   \n",
       "...                             ...                            ...   \n",
       "307506                          0.0                            0.0   \n",
       "307507                          0.0                            0.0   \n",
       "307508                          0.0                            0.0   \n",
       "307509                          0.0                            0.0   \n",
       "307510                          0.0                            0.0   \n",
       "\n",
       "       PrevCodeRejectReasonSystemCount  PrevCodeRejectReasonVerifCount  \\\n",
       "0                                  0.0                             0.0   \n",
       "1                                  0.0                             0.0   \n",
       "2                                  0.0                             0.0   \n",
       "3                                  0.0                             0.0   \n",
       "4                                  0.0                             0.0   \n",
       "...                                ...                             ...   \n",
       "307506                             0.0                             0.0   \n",
       "307507                             0.0                             0.0   \n",
       "307508                             0.0                             0.0   \n",
       "307509                             0.0                             0.0   \n",
       "307510                             0.0                             0.0   \n",
       "\n",
       "        PrevCodeRejectReasonXapCount  PrevCodeRejectReasonXnaCount  \\\n",
       "0                                1.0                           0.0   \n",
       "1                                3.0                           0.0   \n",
       "2                                1.0                           0.0   \n",
       "3                                8.0                           0.0   \n",
       "4                                6.0                           0.0   \n",
       "...                              ...                           ...   \n",
       "307506                           1.0                           0.0   \n",
       "307507                           1.0                           0.0   \n",
       "307508                           2.0                           0.0   \n",
       "307509                           2.0                           0.0   \n",
       "307510                           6.0                           0.0   \n",
       "\n",
       "        PrevLastLoanNflagInsuredOnApproval  PrevAvgNflagInsuredOnApproval  \n",
       "0                                      0.0                       0.000000  \n",
       "1                                      1.0                       0.666667  \n",
       "2                                      0.0                       0.000000  \n",
       "3                                      NaN                       0.000000  \n",
       "4                                      1.0                       0.600000  \n",
       "...                                    ...                            ...  \n",
       "307506                                 0.0                       0.000000  \n",
       "307507                                 1.0                       1.000000  \n",
       "307508                                 0.0                       0.500000  \n",
       "307509                                 1.0                       0.500000  \n",
       "307510                                 NaN                       0.333333  \n",
       "\n",
       "[307511 rows x 227 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NameContractType</th>\n",
       "      <th>CodeGender</th>\n",
       "      <th>FlagOwnCar</th>\n",
       "      <th>FlagOwnRealty</th>\n",
       "      <th>CntChildren</th>\n",
       "      <th>AmtIncomeTotal</th>\n",
       "      <th>AmtCredit</th>\n",
       "      <th>AmtAnnuity</th>\n",
       "      <th>AmtGoodsPrice</th>\n",
       "      <th>...</th>\n",
       "      <th>PrevCodeRejectReasonHcCount</th>\n",
       "      <th>PrevCodeRejectReasonLimitCount</th>\n",
       "      <th>PrevCodeRejectReasonScoCount</th>\n",
       "      <th>PrevCodeRejectReasonScofrCount</th>\n",
       "      <th>PrevCodeRejectReasonSystemCount</th>\n",
       "      <th>PrevCodeRejectReasonVerifCount</th>\n",
       "      <th>PrevCodeRejectReasonXapCount</th>\n",
       "      <th>PrevCodeRejectReasonXnaCount</th>\n",
       "      <th>PrevLastLoanNflagInsuredOnApproval</th>\n",
       "      <th>PrevAvgNflagInsuredOnApproval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307506</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>254700.0</td>\n",
       "      <td>27558.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307507</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>269550.0</td>\n",
       "      <td>12001.5</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307508</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>677664.0</td>\n",
       "      <td>29979.0</td>\n",
       "      <td>585000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307509</th>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>370107.0</td>\n",
       "      <td>20205.0</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307510</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>49117.5</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307511 rows  227 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T17:44:17.806403Z",
     "start_time": "2024-04-20T17:44:17.804201Z"
    }
   },
   "id": "e88fb97a1bdb7db8",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T17:44:17.808241Z",
     "start_time": "2024-04-20T17:44:17.806403Z"
    }
   },
   "id": "b8958a4e18afe0d4",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T17:44:17.810205Z",
     "start_time": "2024-04-20T17:44:17.808241Z"
    }
   },
   "id": "f502809aea6263b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T17:44:17.812824Z",
     "start_time": "2024-04-20T17:44:17.810205Z"
    }
   },
   "id": "f2e21b82c3053120",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T17:44:17.814701Z",
     "start_time": "2024-04-20T17:44:17.812824Z"
    }
   },
   "id": "4cbda67e3cec9bce",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "from Draft.feature_builder_v2 import DatasetType\n",
    "\n",
    "importlib.reload(feature_builder_v2)\n",
    "features_matrix_full = feature_builder_v2.load_datasets_and_prepare_features(drop_meta_data=True,\n",
    "                                                                             ds_type=DatasetType.FULL)\n",
    "features_matrix_base = feature_builder_v2.load_datasets_and_prepare_features(drop_meta_data=True,\n",
    "                                                                             ds_type=DatasetType.BASE)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T17:44:37.458433Z",
     "start_time": "2024-04-20T17:44:17.814701Z"
    }
   },
   "id": "3417c5b9b8374dd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\featuretools\\entityset\\entityset.py:1914: UserWarning: index SK_BUREAU_ID not found in dataframe, creating new integer column\n",
      "  warnings.warn(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\woodwork\\type_sys\\utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\featuretools\\computational_backends\\feature_set_calculator.py:828: FutureWarning: The provided callable <function mean at 0x0000020748304D60> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  ).agg(to_agg)\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\featuretools\\computational_backends\\feature_set_calculator.py:828: FutureWarning: The provided callable <function min at 0x00000207483044A0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
      "  ).agg(to_agg)\n",
      "C:\\Users\\Paulius\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ppuodz-ml-4-1-dqELbViF-py3.12\\Lib\\site-packages\\featuretools\\computational_backends\\feature_set_calculator.py:828: FutureWarning: The provided callable <function max at 0x0000020748304360> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  ).agg(to_agg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending previous history\n",
      "Full DS size: 307511\n",
      "Full DS size: 307511\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "features_matrix_full"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T17:44:37.502277Z",
     "start_time": "2024-04-20T17:44:37.458433Z"
    }
   },
   "id": "af6d9fe4aba1c40",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        TARGET NameContractType CodeGender  FlagOwnCar  FlagOwnRealty  \\\n",
       "0            1       Cash loans          M       False           True   \n",
       "1            0       Cash loans          F       False          False   \n",
       "2            0  Revolving loans          M        True           True   \n",
       "3            0       Cash loans          F       False           True   \n",
       "4            0       Cash loans          M       False           True   \n",
       "...        ...              ...        ...         ...            ...   \n",
       "307506       0       Cash loans          M       False          False   \n",
       "307507       0       Cash loans          F       False           True   \n",
       "307508       0       Cash loans          F       False           True   \n",
       "307509       1       Cash loans          F       False           True   \n",
       "307510       0       Cash loans          F       False          False   \n",
       "\n",
       "        CntChildren  AmtIncomeTotal  AmtCredit  AmtAnnuity  AmtGoodsPrice  \\\n",
       "0                 0        202500.0   406597.5     24700.5       351000.0   \n",
       "1                 0        270000.0  1293502.5     35698.5      1129500.0   \n",
       "2                 0         67500.0   135000.0      6750.0       135000.0   \n",
       "3                 0        135000.0   312682.5     29686.5       297000.0   \n",
       "4                 0        121500.0   513000.0     21865.5       513000.0   \n",
       "...             ...             ...        ...         ...            ...   \n",
       "307506            0        157500.0   254700.0     27558.0       225000.0   \n",
       "307507            0         72000.0   269550.0     12001.5       225000.0   \n",
       "307508            0        153000.0   677664.0     29979.0       585000.0   \n",
       "307509            0        171000.0   370107.0     20205.0       319500.0   \n",
       "307510            0        157500.0   675000.0     49117.5       675000.0   \n",
       "\n",
       "        ... PrevCodeRejectReasonHcCount PrevCodeRejectReasonLimitCount  \\\n",
       "0       ...                         0.0                            0.0   \n",
       "1       ...                         0.0                            0.0   \n",
       "2       ...                         0.0                            0.0   \n",
       "3       ...                         0.0                            1.0   \n",
       "4       ...                         0.0                            0.0   \n",
       "...     ...                         ...                            ...   \n",
       "307506  ...                         0.0                            0.0   \n",
       "307507  ...                         0.0                            0.0   \n",
       "307508  ...                         0.0                            0.0   \n",
       "307509  ...                         0.0                            0.0   \n",
       "307510  ...                         2.0                            0.0   \n",
       "\n",
       "       PrevCodeRejectReasonScoCount PrevCodeRejectReasonScofrCount  \\\n",
       "0                               0.0                            0.0   \n",
       "1                               0.0                            0.0   \n",
       "2                               0.0                            0.0   \n",
       "3                               0.0                            0.0   \n",
       "4                               0.0                            0.0   \n",
       "...                             ...                            ...   \n",
       "307506                          0.0                            0.0   \n",
       "307507                          0.0                            0.0   \n",
       "307508                          0.0                            0.0   \n",
       "307509                          0.0                            0.0   \n",
       "307510                          0.0                            0.0   \n",
       "\n",
       "       PrevCodeRejectReasonSystemCount  PrevCodeRejectReasonVerifCount  \\\n",
       "0                                  0.0                             0.0   \n",
       "1                                  0.0                             0.0   \n",
       "2                                  0.0                             0.0   \n",
       "3                                  0.0                             0.0   \n",
       "4                                  0.0                             0.0   \n",
       "...                                ...                             ...   \n",
       "307506                             0.0                             0.0   \n",
       "307507                             0.0                             0.0   \n",
       "307508                             0.0                             0.0   \n",
       "307509                             0.0                             0.0   \n",
       "307510                             0.0                             0.0   \n",
       "\n",
       "        PrevCodeRejectReasonXapCount  PrevCodeRejectReasonXnaCount  \\\n",
       "0                                1.0                           0.0   \n",
       "1                                3.0                           0.0   \n",
       "2                                1.0                           0.0   \n",
       "3                                8.0                           0.0   \n",
       "4                                6.0                           0.0   \n",
       "...                              ...                           ...   \n",
       "307506                           1.0                           0.0   \n",
       "307507                           1.0                           0.0   \n",
       "307508                           2.0                           0.0   \n",
       "307509                           2.0                           0.0   \n",
       "307510                           6.0                           0.0   \n",
       "\n",
       "        PrevLastLoanNflagInsuredOnApproval  PrevAvgNflagInsuredOnApproval  \n",
       "0                                      0.0                       0.000000  \n",
       "1                                      1.0                       0.666667  \n",
       "2                                      0.0                       0.000000  \n",
       "3                                      NaN                       0.000000  \n",
       "4                                      1.0                       0.600000  \n",
       "...                                    ...                            ...  \n",
       "307506                                 0.0                       0.000000  \n",
       "307507                                 1.0                       1.000000  \n",
       "307508                                 0.0                       0.500000  \n",
       "307509                                 1.0                       0.500000  \n",
       "307510                                 NaN                       0.333333  \n",
       "\n",
       "[307511 rows x 227 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NameContractType</th>\n",
       "      <th>CodeGender</th>\n",
       "      <th>FlagOwnCar</th>\n",
       "      <th>FlagOwnRealty</th>\n",
       "      <th>CntChildren</th>\n",
       "      <th>AmtIncomeTotal</th>\n",
       "      <th>AmtCredit</th>\n",
       "      <th>AmtAnnuity</th>\n",
       "      <th>AmtGoodsPrice</th>\n",
       "      <th>...</th>\n",
       "      <th>PrevCodeRejectReasonHcCount</th>\n",
       "      <th>PrevCodeRejectReasonLimitCount</th>\n",
       "      <th>PrevCodeRejectReasonScoCount</th>\n",
       "      <th>PrevCodeRejectReasonScofrCount</th>\n",
       "      <th>PrevCodeRejectReasonSystemCount</th>\n",
       "      <th>PrevCodeRejectReasonVerifCount</th>\n",
       "      <th>PrevCodeRejectReasonXapCount</th>\n",
       "      <th>PrevCodeRejectReasonXnaCount</th>\n",
       "      <th>PrevLastLoanNflagInsuredOnApproval</th>\n",
       "      <th>PrevAvgNflagInsuredOnApproval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307506</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>254700.0</td>\n",
       "      <td>27558.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307507</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>269550.0</td>\n",
       "      <td>12001.5</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307508</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>677664.0</td>\n",
       "      <td>29979.0</td>\n",
       "      <td>585000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307509</th>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>370107.0</td>\n",
       "      <td>20205.0</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307510</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>49117.5</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307511 rows  227 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "importlib.reload(feature_builder_v2)\n",
    "features_matrix = feature_builder_v2.load_datasets_and_prepare_features(drop_meta_data=True,\n",
    "                                                                        ds_type=feature_builder_v2.DatasetType.BASE_ONLY_CREDIT_RATINGS)\n",
    "from shared import stats_utils\n",
    "\n",
    "stats_utils.nan_summary(features_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T17:44:37.683723Z",
     "start_time": "2024-04-20T17:44:37.502277Z"
    }
   },
   "id": "cdea310c0e82a4aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full DS size: 307511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            Total NaN Values  Proportion NaN (%)\n",
       "ExtSource1            173378                56.0\n",
       "ExtSource2               660                 0.0\n",
       "ExtSource3             60965                20.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total NaN Values</th>\n",
       "      <th>Proportion NaN (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExtSource1</th>\n",
       "      <td>173378</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtSource2</th>\n",
       "      <td>660</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtSource3</th>\n",
       "      <td>60965</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T17:44:37.685801Z",
     "start_time": "2024-04-20T17:44:37.683723Z"
    }
   },
   "id": "37dad6ce569a8ada",
   "outputs": [],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
